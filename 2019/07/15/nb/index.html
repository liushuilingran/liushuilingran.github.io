<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>朴素贝叶斯 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/images/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="介绍&amp;amp;emsp;&amp;amp;emsp;朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶"><meta property="og:type" content="blog"><meta property="og:title" content="朴素贝叶斯"><meta property="og:url" content="https://huzhiliang.com/2019/07/15/nb/"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="介绍&amp;amp;emsp;&amp;amp;emsp;朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://huzhiliang.com/gallery/22.jpg"><meta property="article:published_time" content="2019-07-15T08:00:26.000Z"><meta property="article:modified_time" content="2019-07-16T16:52:55.706Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="spark"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/22.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://huzhiliang.com/2019/07/15/nb/"},"headline":"MCFON","image":["https://huzhiliang.com/gallery/22.jpg"],"datePublished":"2019-07-15T08:00:26.000Z","dateModified":"2019-07-16T16:52:55.706Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"description":"介绍&amp;emsp;&amp;emsp;朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关。举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶"}</script><link rel="canonical" href="https://huzhiliang.com/2019/07/15/nb/"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-07-15T08:00:26.000Z" title="2019-07-15T08:00:26.000Z">2019-07-15</time>发表</span><span class="level-item"><time dateTime="2019-07-16T16:52:55.706Z" title="2019-07-16T16:52:55.706Z">2019-07-17</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span><span class="level-item">25 分钟读完 (大约3780个字)</span><span class="level-item leancloud_visitors" id="/2019/07/15/nb/" data-flag-title="朴素贝叶斯"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="twikoo_visitors"><i class="fa fa-spinner fa-spin"></i></span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">朴素贝叶斯</h1><div class="content"><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>&emsp;&emsp;朴素贝叶斯是一种构建分类器的简单方法。该分类器模型会给问题实例分配用特征值表示的类标签，类标签取自有限集合。它不是训练这种分类器的单一算法，而是一系列基于相同原理的算法：<strong>所有朴素贝叶斯分类器都假定样本每个特征与其他特征都不相关</strong>。<br>举个例子，如果一种水果其具有红，圆，直径大概3英寸等特征，该水果可以被判定为是苹果。尽管这些特征相互依赖或者有些特征由其他特征决定，然而朴素贝叶斯分类器认为这些属性在判定该水果是否为苹果的概率分布上独立的。</p>
<a id="more"></a>
<p>&emsp;&emsp;对于某些类型的概率模型，在有监督学习的样本集中能获取得非常好的分类效果。在许多实际应用中，朴素贝叶斯模型参数估计使用最大似然估计方法；换言之，在不用贝叶斯概率或者任何贝叶斯模型的情况下，朴素贝叶斯模型也能奏效。</p>
<p>&emsp;&emsp;尽管是带着这些朴素思想和过于简单化的假设，但朴素贝叶斯分类器在很多复杂的现实情形中仍能够取得相当好的效果。尽管如此，有论文证明更新的方法（如提升树和随机森林）的性能超过了贝叶斯分类器。</p>
<p>&emsp;&emsp;朴素贝叶斯分类器的一个优势在于只需要根据少量的训练数据估计出必要的参数（变量的均值和方差）。由于变量独立假设，只需要估计各个变量，而不需要确定整个协方差矩阵。</p>
<h3 id="朴素贝叶斯的优缺点"><a href="#朴素贝叶斯的优缺点" class="headerlink" title="朴素贝叶斯的优缺点"></a>朴素贝叶斯的优缺点</h3><ul>
<li><p>优点：学习和预测的效率高，且易于实现；在数据较少的情况下仍然有效，可以处理多分类问题。</p>
</li>
<li><p>缺点：分类效果不一定很高，特征独立性假设会是朴素贝叶斯变得简单，但是会牺牲一定的分类准确率。</p>
</li>
</ul>
<h2 id="朴素贝叶斯概率模型"><a href="#朴素贝叶斯概率模型" class="headerlink" title="朴素贝叶斯概率模型"></a>朴素贝叶斯概率模型</h2><p>&emsp;&emsp;理论上，概率模型分类器是一个条件概率模型。</p>
<div  align="center"><img src="../images/imgs3/1.1.png" width = "130" height = "20" alt="1.1" align="center" /></div>

<p>&emsp;&emsp;独立的类别变量<code>C</code>有若干类别，条件依赖于若干特征变量<code>F_1,F_2,...,F_n</code>。但问题在于如果特征数量<code>n</code>较大或者每个特征能取大量值时，基于概率模型列出概率表变得不现实。所以我们修改这个模型使之变得可行。 贝叶斯定理有以下式子：</p>
<div  align="center"><img src="../images/imgs3/1.2.png" width = "350" height = "50" alt="1.2" align="center" /></div>

<p>&emsp;&emsp;实际中，我们只关心分式中的分子部分，因为分母不依赖于<code>C</code>而且特征<code>F_i</code>的值是给定的，于是分母可以认为是一个常数。这样分子就等价于联合分布模型。<br>重复使用链式法则，可将该式写成条件概率的形式，如下所示：</p>
<div  align="center"><img src="../images/imgs3/1.3.png" width = "765" height = "137" alt="1.3" align="center" /></div>

<p>&emsp;&emsp;现在“朴素”的条件独立假设开始发挥作用:假设每个特征<code>F_i</code>对于其他特征<code>F_j</code>是条件独立的。这就意味着</p>
<div  align="center"><img src="../images/imgs3/1.4.png" width = "180" height = "21" alt="1.4" align="center" /></div>

<p>&emsp;&emsp;所以联合分布模型可以表达为</p>
<div  align="center"><img src="../images/imgs3/1.5.png" width = "450" height = "87" alt="1.5" align="center" /></div>

<p>&emsp;&emsp;这意味着上述假设下，类变量<code>C</code>的条件分布可以表达为：</p>
<div  align="center"><img src="../images/imgs3/1.6.png" width = "310" height = "48" alt="1.6" align="center" /></div>

<p>&emsp;&emsp;其中<code>Z</code>是一个只依赖与<code>F_1,...,F_n</code>等的缩放因子，当特征变量的值已知时是一个常数。</p>
<h3 id="从概率模型中构造分类器"><a href="#从概率模型中构造分类器" class="headerlink" title="从概率模型中构造分类器"></a>从概率模型中构造分类器</h3><p>&emsp;&emsp;讨论至此为止我们导出了独立分布特征模型，也就是朴素贝叶斯概率模型。朴素贝叶斯分类器包括了这种模型和相应的决策规则。一个普通的规则就是选出最有可能的那个：这就是大家熟知的最大后验概率（<code>MAP</code>）决策准则。相应的分类器便是如下定义的公式：</p>
<div  align="center"><img src="../images/imgs3/1.7.png" width = "500" height = "55" alt="1.7" align="center" /></div>

<h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>&emsp;&emsp;所有的模型参数都可以通过训练集的相关频率来估计。常用方法是概率的最大似然估计。类的先验概率<code>P(C)</code>可以通过假设各类等概率来计算<code>（先验概率 = 1 / (类的数量)）</code>，或者通过训练集的各类样本出现的次数来估计<code>（A类先验概率=（A类样本的数量）/(样本总数)）</code>。</p>
<p>&emsp;&emsp;对于类条件概率<code>P(X|c)</code>来说，直接根据样本出现的频率来估计会很困难。在现实应用中样本空间的取值往往远远大于训练样本数，也就是说，很多样本取值在训练集中根本没有出现，直接使用频率来估计<code>P(x|c)</code>不可行，因为”未被观察到”和”出现概率为零”是不同的。<br>为了估计特征的分布参数，我们要先假设训练集数据满足某种分布或者非参数模型。</p>
<p>&emsp;&emsp;这种假设称为朴素贝叶斯分类器的事件模型（<code>event model</code>）。对于离散的特征数据（例如文本分类中使用的特征），多元分布和伯努利分布比较流行。</p>
<h3 id="高斯朴素贝叶斯"><a href="#高斯朴素贝叶斯" class="headerlink" title="高斯朴素贝叶斯"></a>高斯朴素贝叶斯</h3><p>&emsp;&emsp;如果要处理的是连续数据，一种通常的假设是这些连续数值服从高斯分布。例如，假设训练集中有一个连续属性<code>x</code>。我们首先对数据根据类别分类，然后计算每个类别中<code>x</code>的均值和方差。令<code>mu_c</code>表示为<code>x</code>在<code>c</code>类上的均值，令<code>sigma^2_c</code>为<code>x</code>在<code>c</code>类上的方差。在给定类中某个值的概率<br><code>P(x=v|c)</code>，可以通过将<code>v</code>表示为均值为<code>mu_c</code>，方差为<code>sigma^2_c</code>的正态分布计算出来。</p>
<div  align="center"><img src="../images/imgs3/1.8.png" width = "250" height = "60" alt="1.8" align="center" /></div>

<p>&emsp;&emsp;处理连续数值问题的另一种常用的技术是通过离散化连续数值的方法。通常，当训练样本数量较少或者是精确的分布已知时，通过概率分布的方法是一种更好的选择。<br>在大量样本的情形下离散化的方法表现更优，因为大量的样本可以学习到数据的分布。由于朴素贝叶斯是一种典型的用到大量样本的方法（越大计算量的模型可以产生越高的分类精确度），所以朴素贝叶斯方法都用到离散化方法，而不是概率分布估计的方法。</p>
<h3 id="多元朴素贝叶斯"><a href="#多元朴素贝叶斯" class="headerlink" title="多元朴素贝叶斯"></a>多元朴素贝叶斯</h3><p>&emsp;&emsp;在多元事件模型中，样本（特征向量）表示特定事件发生的次数。用<code>p_i</code>表示事件<code>i</code>发生的概率。特征向量<code>X=(x_1,x_2,...,x_n)</code>是一个<code>histogram</code>，其中<code>x_i</code>表示事件<code>i</code>在特定的对象中被观察到的次数。事件模型通常用于文本分类。相应的<code>x_i</code>表示词<code>i</code>在单个文档中出现的次数。<br><code>X</code>的似然函数如下所示：</p>
<div  align="center"><img src="../images/imgs3/2.1.png" width = "230" height = "53" alt="2.1" align="center" /></div>

<p>&emsp;&emsp;当用对数空间表达时，多元朴素贝叶斯分类器变成了线性分类器。</p>
<div  align="center"><img src="../images/imgs3/2.2.png" width = "340" height = "155" alt="2.2" align="center" /></div>

<p>&emsp;&emsp;如果一个给定的类和特征值在训练集中没有一起出现过，那么基于频率的估计下该概率将为0。这将是一个问题。因为与其他概率相乘时将会把其他概率的信息统统去除。所以常常要求要对每个小类样本的概率估计进行修正，以保证不会出现有为0的概率出现。常用到的平滑就是加1平滑（也称拉普拉斯平滑）。</p>
<p>&emsp;&emsp;根据参考文献【2】，我们以文本分类的训练和测试为例子来介绍多元朴素贝叶斯的训练和测试过程。如下图所示。</p>
<div  align="center"><img src="../images/imgs3/2.3.png" width = "460" height = "390" alt="2.3" align="center" /></div>

<p>&emsp;&emsp;这里的<code>CondProb[t][c]</code>即上文中的<code>P(x|C)</code>。<code>T_ct</code>表示类别为<code>c</code>的文档中<code>t</code>出现的次数。<code>+1</code>就是平滑手段。</p>
<h3 id="伯努利朴素贝叶斯"><a href="#伯努利朴素贝叶斯" class="headerlink" title="伯努利朴素贝叶斯"></a>伯努利朴素贝叶斯</h3><p>&emsp;&emsp;在多变量伯努利事件模型中，特征是独立的二值变量。和多元模型一样，这个模型在文本分类中也非常流行。它的似然函数如下所示。</p>
<div  align="center"><img src="../images/imgs3/3.1.png" width = "260" height = "55" alt="3.1" align="center" /></div>

<p>&emsp;&emsp;其中<code>p_ki</code>表示类别<code>C_k</code>生成<code>term</code> <code>w_i</code>的概率。这个模型通常用于短文本分类。</p>
<p>&emsp;&emsp;根据参考文献【2】，我们以文本分类的训练和测试为例子来介绍多元朴素贝叶斯的训练和测试过程。如下图所示。</p>
<div  align="center"><img src="../images/imgs3/3.2.png" width = "555" height = "450" alt="3.2" align="center" /></div>


<h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><p>&emsp;&emsp;<code>MLlib</code>中实现了多元朴素贝叶斯和伯努利朴素贝叶斯。下面先看看朴素贝叶斯的使用实例。</p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.classification.&#123;<span class="type">NaiveBayes</span>, <span class="type">NaiveBayesModel</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.regression.<span class="type">LabeledPoint</span></span><br><span class="line"><span class="comment">//读取并处理数据</span></span><br><span class="line"><span class="keyword">val</span> data = sc.textFile(<span class="string">&quot;data/mllib/sample_naive_bayes_data.txt&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> parsedData = data.map &#123; line =&gt;</span><br><span class="line">  <span class="keyword">val</span> parts = line.split(&#x27;,&#x27;)</span><br><span class="line">  <span class="type">LabeledPoint</span>(parts(<span class="number">0</span>).toDouble, <span class="type">Vectors</span>.dense(parts(<span class="number">1</span>).split(&#x27; &#x27;).map(_.toDouble)))</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 切分数据为训练数据和测试数据</span></span><br><span class="line"><span class="keyword">val</span> splits = parsedData.randomSplit(<span class="type">Array</span>(<span class="number">0.6</span>, <span class="number">0.4</span>), seed = <span class="number">11</span>L)</span><br><span class="line"><span class="keyword">val</span> training = splits(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">val</span> test = splits(<span class="number">1</span>)</span><br><span class="line"><span class="comment">//训练模型</span></span><br><span class="line"><span class="keyword">val</span> model = <span class="type">NaiveBayes</span>.train(training, lambda = <span class="number">1.0</span>, modelType = <span class="string">&quot;multinomial&quot;</span>)</span><br><span class="line"><span class="comment">//测试数据</span></span><br><span class="line"><span class="keyword">val</span> predictionAndLabel = test.map(p =&gt; (model.predict(p.features), p.label))</span><br><span class="line"><span class="keyword">val</span> accuracy = <span class="number">1.0</span> * predictionAndLabel.filter(x =&gt; x._1 == x._2).count() / test.count()</span><br></pre></td></tr></table></figure>
<h3 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h3><p>&emsp;&emsp;从上文的原理分析我们可以知道，朴素贝叶斯模型的训练过程就是获取概率<code>p(C)</code>和<code>p(F|C)</code>的过程。根据<code>MLlib</code>的源码，我们可以将训练过程分为两步。<br>第一步是聚合计算每个标签对应的<code>term</code>的频率，第二步是迭代计算<code>p(C)</code>和<code>p(F|C)</code>。</p>
<ul>
<li><strong>1</strong> 计算每个标签对应的<code>term</code>的频率</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> aggregated = data.map(p =&gt; (p.label, p.features)).combineByKey[(<span class="type">Long</span>, <span class="type">DenseVector</span>)](</span><br><span class="line">      createCombiner = (v: <span class="type">Vector</span>) =&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (modelType == <span class="type">Bernoulli</span>) &#123;</span><br><span class="line">          requireZeroOneBernoulliValues(v)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          requireNonnegativeValues(v)</span><br><span class="line">        &#125;</span><br><span class="line">        (<span class="number">1</span>L, v.copy.toDense)</span><br><span class="line">      &#125;,</span><br><span class="line">      mergeValue = (c: (<span class="type">Long</span>, <span class="type">DenseVector</span>), v: <span class="type">Vector</span>) =&gt; &#123;</span><br><span class="line">        requireNonnegativeValues(v)</span><br><span class="line">        <span class="comment">//c._2 = v*1 + c._2</span></span><br><span class="line">        <span class="type">BLAS</span>.axpy(<span class="number">1.0</span>, v, c._2)</span><br><span class="line">        (c._1 + <span class="number">1</span>L, c._2)</span><br><span class="line">      &#125;,</span><br><span class="line">      mergeCombiners = (c1: (<span class="type">Long</span>, <span class="type">DenseVector</span>), c2: (<span class="type">Long</span>, <span class="type">DenseVector</span>)) =&gt; &#123;</span><br><span class="line">        <span class="type">BLAS</span>.axpy(<span class="number">1.0</span>, c2._2, c1._2)</span><br><span class="line">        (c1._1 + c2._1, c1._2)</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment">//根据标签进行排序</span></span><br><span class="line">    ).collect().sortBy(_._1)</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这里我们需要先了解<code>createCombiner</code>函数的作用。<code>createCombiner</code>的作用是将原<code>RDD</code>中的<code>Vector</code>类型转换为<code>(long,Vector)</code>类型。</p>
<p>&emsp;&emsp;如果<code>modelType</code>为<code>Bernoulli</code>，那么<code>v</code>中包含的值只能为0或者1。如果<code>modelType</code>为<code>multinomial</code>，那么<code>v</code>中包含的值必须大于0。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//值非负</span></span><br><span class="line"><span class="keyword">val</span> requireNonnegativeValues: <span class="type">Vector</span> =&gt; <span class="type">Unit</span> = (v: <span class="type">Vector</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> values = v <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> sv: <span class="type">SparseVector</span> =&gt; sv.values</span><br><span class="line">        <span class="keyword">case</span> dv: <span class="type">DenseVector</span> =&gt; dv.values</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!values.forall(_ &gt;= <span class="number">0.0</span>)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s&quot;Naive Bayes requires nonnegative feature values but found <span class="subst">$v</span>.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//值为0或者1</span></span><br><span class="line"><span class="keyword">val</span> requireZeroOneBernoulliValues: <span class="type">Vector</span> =&gt; <span class="type">Unit</span> = (v: <span class="type">Vector</span>) =&gt; &#123;</span><br><span class="line">      <span class="keyword">val</span> values = v <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> sv: <span class="type">SparseVector</span> =&gt; sv.values</span><br><span class="line">        <span class="keyword">case</span> dv: <span class="type">DenseVector</span> =&gt; dv.values</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!values.forall(v =&gt; v == <span class="number">0.0</span> || v == <span class="number">1.0</span>)) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(</span><br><span class="line">          <span class="string">s&quot;Bernoulli naive Bayes requires 0 or 1 feature values but found <span class="subst">$v</span>.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;<code>mergeValue</code>函数的作用是将新来的<code>Vector</code>累加到已有向量中，并更新词率。<code>mergeCombiners</code>则是合并不同分区的<code>(long,Vector)</code>数据。<br>通过这个函数，我们就找到了每个标签对应的词频率，并得到了标签对应的所有文档的累加向量。</p>
<ul>
<li><strong>2</strong> 迭代计算<code>p(C)</code>和<code>p(F|C)</code></li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//标签数</span></span><br><span class="line"><span class="keyword">val</span> numLabels = aggregated.length</span><br><span class="line"><span class="comment">//文档数</span></span><br><span class="line"><span class="keyword">var</span> numDocuments = <span class="number">0</span>L</span><br><span class="line">aggregated.foreach &#123; <span class="keyword">case</span> (_, (n, _)) =&gt;</span><br><span class="line">  numDocuments += n</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//特征维数</span></span><br><span class="line"><span class="keyword">val</span> numFeatures = aggregated.head <span class="keyword">match</span> &#123; <span class="keyword">case</span> (_, (_, v)) =&gt; v.size &#125;</span><br><span class="line"><span class="keyword">val</span> labels = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Double</span>](numLabels)</span><br><span class="line"><span class="comment">//表示logP(C)</span></span><br><span class="line"><span class="keyword">val</span> pi = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Double</span>](numLabels)</span><br><span class="line"><span class="comment">//表示logP(F|C)</span></span><br><span class="line"><span class="keyword">val</span> theta = <span class="type">Array</span>.fill(numLabels)(<span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Double</span>](numFeatures))</span><br><span class="line"><span class="keyword">val</span> piLogDenom = math.log(numDocuments + numLabels * lambda)</span><br><span class="line"><span class="keyword">var</span> i = <span class="number">0</span></span><br><span class="line">aggregated.foreach &#123; <span class="keyword">case</span> (label, (n, sumTermFreqs)) =&gt;</span><br><span class="line">      labels(i) = label</span><br><span class="line">      <span class="comment">//训练步骤的第5步</span></span><br><span class="line">      pi(i) = math.log(n + lambda) - piLogDenom</span><br><span class="line">      <span class="keyword">val</span> thetaLogDenom = modelType <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Multinomial</span> =&gt; math.log(sumTermFreqs.values.sum + numFeatures * lambda)</span><br><span class="line">        <span class="keyword">case</span> <span class="type">Bernoulli</span> =&gt; math.log(n + <span class="number">2.0</span> * lambda)</span><br><span class="line">        <span class="keyword">case</span> _ =&gt;</span><br><span class="line">          <span class="comment">// This should never happen.</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownError</span>(<span class="string">s&quot;Invalid modelType: <span class="subst">$modelType</span>.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//训练步骤的第6步</span></span><br><span class="line">      <span class="keyword">var</span> j = <span class="number">0</span></span><br><span class="line">      <span class="keyword">while</span> (j &lt; numFeatures) &#123;</span><br><span class="line">        theta(i)(j) = math.log(sumTermFreqs(j) + lambda) - thetaLogDenom</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">      &#125;</span><br><span class="line">      i += <span class="number">1</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这段代码计算上文提到的<code>p(C)</code>和<code>p(F|C)</code>。这里的<code>lambda</code>表示平滑因子，一般情况下，我们将它设置为1。代码中，<code>p(c_i)=log (n+lambda)/(numDocs+numLabels*lambda)</code>，这对应上文训练过程的第5步<code>prior(c)=N_c/N</code>。</p>
<p>&emsp;&emsp;根据<code>modelType</code>类型的不同，<code>p(F|C)</code>的实现则不同。当<code>modelType</code>为<code>Multinomial</code>时，<code>P(F|C)=T_ct/sum(T_ct)</code>，这里<code>sum(T_ct)=sumTermFreqs.values.sum + numFeatures * lambda</code>。这对应多元朴素贝叶斯训练过程的第10步。<br>当<code>modelType</code>为<code>Bernoulli</code>时，<code>P(F|C)=(N_ct+lambda)/(N_c+2*lambda)</code>。这对应伯努利贝叶斯训练算法的第8行。</p>
<p>&emsp;&emsp;需要注意的是，代码中的所有计算都是取对数计算的。</p>
<h2 id="预测数据"><a href="#预测数据" class="headerlink" title="预测数据"></a>预测数据</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">predict</span></span>(testData: <span class="type">Vector</span>): <span class="type">Double</span> = &#123;</span><br><span class="line">    modelType <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Multinomial</span> =&gt;</span><br><span class="line">        labels(multinomialCalculation(testData).argmax)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Bernoulli</span> =&gt;</span><br><span class="line">        labels(bernoulliCalculation(testData).argmax)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;预测也是根据<code>modelType</code>的不同作不同的处理。当<code>modelType</code>为<code>Multinomial</code>时，调用<code>multinomialCalculation</code>函数。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">multinomialCalculation</span></span>(testData: <span class="type">Vector</span>) = &#123;</span><br><span class="line">    <span class="keyword">val</span> prob = thetaMatrix.multiply(testData)</span><br><span class="line">    <span class="type">BLAS</span>.axpy(<span class="number">1.0</span>, piVector, prob)</span><br><span class="line">    prob</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这里的<code>thetaMatrix</code>和<code>piVector</code>即上文中训练得到的<code>P(F|C)</code>和<code>P(C)</code>，根据<code>P(C|F)=P(F|C)*P(C)</code>即可以得到预测数据归属于某类别的概率。<br>注意，这些概率都是基于对数结果计算的。</p>
<p>&emsp;&emsp;当<code>modelType</code>为<code>Bernoulli</code>时，实现代码略有不同。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">bernoulliCalculation</span></span>(testData: <span class="type">Vector</span>) = &#123;</span><br><span class="line">    testData.foreachActive((_, value) =&gt;</span><br><span class="line">      <span class="keyword">if</span> (value != <span class="number">0.0</span> &amp;&amp; value != <span class="number">1.0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(</span><br><span class="line">          <span class="string">s&quot;Bernoulli naive Bayes requires 0 or 1 feature values but found <span class="subst">$testData</span>.&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">val</span> prob = thetaMinusNegTheta.get.multiply(testData)</span><br><span class="line">    <span class="type">BLAS</span>.axpy(<span class="number">1.0</span>, piVector, prob)</span><br><span class="line">    <span class="type">BLAS</span>.axpy(<span class="number">1.0</span>, negThetaSum.get, prob)</span><br><span class="line">    prob</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;当词在训练数据中出现与否处理的过程不同。伯努利模型测试过程中，如果词存在，需要计算<code>log(condprob)</code>，否在需要计算<code>log(1-condprob)</code>，<code>condprob</code>为<code>P(f|c)=exp(theta)</code>。所以预先计算<code>log(1-exp(theta))</code>以及它的和可以应用到预测过程。这里<code>thetaMatrix</code>表示<code>logP(F|C)</code>，<code>negTheta</code>代表<code>log(1-exp(theta))=log(1-condprob)</code>，<code>thetaMinusNegTheta</code>代表<code>log(theta - log(1-exp(theta)))</code>。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> (thetaMinusNegTheta, negThetaSum) = modelType <span class="keyword">match</span> &#123;</span><br><span class="line">   <span class="keyword">case</span> <span class="type">Multinomial</span> =&gt; (<span class="type">None</span>, <span class="type">None</span>)</span><br><span class="line">   <span class="keyword">case</span> <span class="type">Bernoulli</span> =&gt;</span><br><span class="line">     <span class="keyword">val</span> negTheta = thetaMatrix.map(value =&gt; math.log(<span class="number">1.0</span> - math.exp(value)))</span><br><span class="line">     <span class="keyword">val</span> ones = <span class="keyword">new</span> <span class="type">DenseVector</span>(<span class="type">Array</span>.fill(thetaMatrix.numCols)&#123;<span class="number">1.0</span>&#125;)</span><br><span class="line">     <span class="keyword">val</span> thetaMinusNegTheta = thetaMatrix.map &#123; value =&gt;</span><br><span class="line">       value - math.log(<span class="number">1.0</span> - math.exp(value))</span><br><span class="line">     &#125;</span><br><span class="line">     (<span class="type">Option</span>(thetaMinusNegTheta), <span class="type">Option</span>(negTheta.multiply(ones)))</span><br><span class="line">   <span class="keyword">case</span> _ =&gt;</span><br><span class="line">     <span class="comment">// This should never happen.</span></span><br><span class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">UnknownError</span>(<span class="string">s&quot;Invalid modelType: <span class="subst">$modelType</span>.&quot;</span>)</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;这里<code>math.exp(value)</code>将对数概率恢复成真实的概率。</p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p>【1】<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8">朴素贝叶斯分类器</a></p>
<p>【2】<a target="_blank" rel="noopener" href="http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html">Naive Bayes text classification</a></p>
<p>【3】<a target="_blank" rel="noopener" href="http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html">The Bernoulli model</a></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>朴素贝叶斯</p><p><a href="https://huzhiliang.com/2019/07/15/nb/">https://huzhiliang.com/2019/07/15/nb/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-07-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-07-17</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/spark/">spark</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><div class="card"><nav class="post-navigation mt-4 level is-mobile card-content"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/07/16/decision-tree/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">决策树</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/07/14/survival-regression/"><span class="level-item">生存回归</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">161</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">97</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener" id="widget-follow">微博 Weibo</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div><a class="link-more button is-light is-small size-small" href="/friends/">查看更多</a></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Golang/"><span class="level-start"><span class="level-item">Golang</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/LeetCode/"><span class="level-start"><span class="level-item">LeetCode</span></span><span class="level-end"><span class="level-item tag">85</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="level-start"><span class="level-item">数据结构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">29</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"><span class="level-start"><span class="level-item">CNN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">迁移学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%A0%B4%E8%A7%A3/"><span class="level-start"><span class="level-item">破解</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">英语学习</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-05T05:41:28.000Z">2020-03-05</time></p><p class="title"><a href="/2020/03/05/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%89-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E8%A7%A3%E7%A0%81/">条件随机场CRF(三) 模型学习与维特比算法解码</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-04T08:24:55.000Z">2020-03-04</time></p><p class="title"><a href="/2020/03/04/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%BA%8C-%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A0%87%E8%AE%B0%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87/">条件随机场CRF(二) 前向后向算法评估标记序列概率</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-03T02:59:49.000Z">2020-03-03</time></p><p class="title"><a href="/2020/03/03/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%80-%E4%BB%8E%E9%9A%8F%E6%9C%BA%E5%9C%BA%E5%88%B0%E7%BA%BF%E6%80%A7%E9%93%BE%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">条件随机场CRF(一)从随机场到线性链条件随机场</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-02T02:46:01.000Z">2020-03-02</time></p><p class="title"><a href="/2020/03/02/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E7%9A%84%E5%88%86%E8%AF%8D%E5%8E%9F%E7%90%86/">文本挖掘的分词原理</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-02-20T01:01:00.000Z">2020-02-20</time></p><p class="title"><a href="/2020/02/20/optimize-water-distribution-in-a-village/">optimize water distribution in a village</a></p><p class="categories"><a href="/categories/LeetCode/">LeetCode</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">一月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">十二月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">十一月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">九月 2019</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">七月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">八月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/02/"><span class="level-start"><span class="level-item">二月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/01/"><span class="level-start"><span class="level-item">一月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/12/"><span class="level-start"><span class="level-item">十二月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/11/"><span class="level-start"><span class="level-item">十一月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/10/"><span class="level-start"><span class="level-item">十月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/09/"><span class="level-start"><span class="level-item">九月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/07/"><span class="level-start"><span class="level-item">七月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/06/"><span class="level-start"><span class="level-item">六月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/05/"><span class="level-start"><span class="level-item">五月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/03/"><span class="level-start"><span class="level-item">三月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/02/"><span class="level-start"><span class="level-item">二月 2017</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/04/"><span class="level-start"><span class="level-item">四月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/02/"><span class="level-start"><span class="level-item">二月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CFG/"><span class="tag">CFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CYK/"><span class="tag">CYK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Caffee/"><span class="tag">Caffee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English/"><span class="tag">English</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Facebook/"><span class="tag">Facebook</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GBDT/"><span class="tag">GBDT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPU/"><span class="tag">GPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GRN/"><span class="tag">GRN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GloVe/"><span class="tag">GloVe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Google-apac/"><span class="tag">Google apac</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go%E8%AF%AD%E8%A8%80/"><span class="tag">Go语言</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Greedy/"><span class="tag">Greedy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HMM/"><span class="tag">HMM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IBM-Modes/"><span class="tag">IBM Modes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL%E6%95%A3%E5%BA%A6/"><span class="tag">KL散度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LeetCode/"><span class="tag">LeetCode</span><span class="tag">31</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexicalized-PCFG/"><span class="tag">Lexicalized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexized-PCFG/"><span class="tag">Lexized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Linear-Models/"><span class="tag">Log-Linear Models</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PCFG/"><span class="tag">PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Programmer/"><span class="tag">Programmer</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Queue/"><span class="tag">Queue</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Seq2seq/"><span class="tag">Seq2seq</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tagging/"><span class="tag">Tagging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tencent/"><span class="tag">Tencent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VIP/"><span class="tag">VIP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Viterbi/"><span class="tag">Viterbi</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-representation/"><span class="tag">Word representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XGBoost/"><span class="tag">XGBoost</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/exhaustive-search/"><span class="tag">exhaustive search</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/turtle/"><span class="tag">turtle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%93%E9%A2%98/"><span class="tag">专题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"><span class="tag">二分搜索</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91/"><span class="tag">二分搜索树</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%A0%91/"><span class="tag">二分树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"><span class="tag">二进制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"><span class="tag">优化算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E7%B1%BB/"><span class="tag">分类</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E8%AF%8D/"><span class="tag">分词</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%91%E6%8C%87offer/"><span class="tag">剑指offer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E5%9B%9E%E5%BD%92/"><span class="tag">动态回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"><span class="tag">动态规划</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%9E%E5%BD%92/"><span class="tag">回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E8%AE%BA/"><span class="tag">图论</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F/"><span class="tag">排序</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"><span class="tag">数学原理</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="tag">数据分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"><span class="tag">条件随机场</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6/"><span class="tag">极大似然</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"><span class="tag">模型压缩</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/"><span class="tag">模型部署</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%88%E6%9D%83/"><span class="tag">版权</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/"><span class="tag">特征抽取</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"><span class="tag">算法原理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/"><span class="tag">算法复杂度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">线性模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%84%E5%90%88%E6%A0%91/"><span class="tag">组合树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"><span class="tag">经典网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"><span class="tag">统计机器翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90/"><span class="tag">网易云音乐</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%81%9A%E7%B1%BB/"><span class="tag">聚类</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"><span class="tag">背包问题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%84%9A%E6%9C%AC/"><span class="tag">脚本</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E6%B3%95/"><span class="tag">语法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><span class="tag">语言模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4/"><span class="tag">超参数调整</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="tag">迁移学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%92%E5%BD%92/"><span class="tag">递归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%82%AE%E4%BB%B6/"><span class="tag">邮件</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%93%BE%E8%A1%A8/"><span class="tag">链表</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%99%8D%E7%BB%B4/"><span class="tag">降维</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95%E4%B8%93%E5%9C%BA/"><span class="tag">面试专场</span><span class="tag">2</span></a></div></div></div></div></div><div class="card widget" id="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2020 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><a href="http://www.miitbeian.gov.cn" target="_blank">豫ICP备18017229号</a> - </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/live2d/autoload.js"></script></body></html>