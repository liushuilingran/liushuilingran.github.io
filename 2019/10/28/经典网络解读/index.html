<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>经典网络解读 - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="LeNet-5模型介绍​    LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操"><meta property="og:type" content="blog"><meta property="og:title" content="经典网络解读"><meta property="og:url" content="https://huzhiliang.com/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="LeNet-5模型介绍​    LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebi5531kj32rx0u07wi.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebiq3vr0j30du04l0td.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebj74qa8j30pw0cwgo3.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebjy8o5ej339v0u0b29.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebk63lrrj30pw094wfw.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkda5gmj309a03vt94.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkkk3gkj30ez04mdgk.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebl3ag0gj32yn0u01ky.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8eblp18bwj30d207odge.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebm42jyij30ic0d4jt6.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebnslykaj30zi0hu0vd.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8eboig32aj30lc0bvjsb.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebp5bpf8j31690u00yz.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebpn1fxkj30ez0ebq3l.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebq7rn4mj30ey0fpmxy.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebqp08eqj30lr0g9myd.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebr0kw83j306s0d7aah.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebrnp4g3j30an0vo0ui.jpg"><meta property="og:image" content="https://huzhiliang.com/2019/10/28/images/image47.png"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebv0xlahj30960obwfw.jpg"><meta property="article:published_time" content="2019-10-28T15:10:28.000Z"><meta property="article:modified_time" content="2019-10-29T05:22:51.176Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="经典网络"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebi5531kj32rx0u07wi.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://huzhiliang.com/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/"},"headline":"MCFON","image":["https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebi5531kj32rx0u07wi.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebiq3vr0j30du04l0td.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebj74qa8j30pw0cwgo3.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebjy8o5ej339v0u0b29.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebk63lrrj30pw094wfw.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkda5gmj309a03vt94.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkkk3gkj30ez04mdgk.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebl3ag0gj32yn0u01ky.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8eblp18bwj30d207odge.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebm42jyij30ic0d4jt6.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebnslykaj30zi0hu0vd.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8eboig32aj30lc0bvjsb.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebp5bpf8j31690u00yz.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebpn1fxkj30ez0ebq3l.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebq7rn4mj30ey0fpmxy.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebqp08eqj30lr0g9myd.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebr0kw83j306s0d7aah.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebrnp4g3j30an0vo0ui.jpg","https://huzhiliang.com/2019/10/28/images/image47.png","https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebv0xlahj30960obwfw.jpg"],"datePublished":"2019-10-28T15:10:28.000Z","dateModified":"2019-10-29T05:22:51.176Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"description":"LeNet-5模型介绍​    LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操"}</script><link rel="canonical" href="https://huzhiliang.com/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives/">时间轴</a><a class="navbar-item" href="/categories/">分类</a><a class="navbar-item" href="/tags/">标签</a><a class="navbar-item" target="_blank" rel="noopener" href="https://imaegoo.azurewebsites.net">网盘</a><a class="navbar-item" href="/messages/">留言板</a><a class="navbar-item" href="/friends/">友情链接</a><a class="navbar-item" href="/about/">关于</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-10-28T15:10:28.000Z" title="2019-10-28T15:10:28.000Z">2019-10-28</time>发表</span><span class="level-item"><time dateTime="2019-10-29T05:22:51.176Z" title="2019-10-29T05:22:51.176Z">2019-10-29</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">43 分钟读完 (大约6474个字)</span><span class="level-item leancloud_visitors" id="/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/" data-flag-title="经典网络解读"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="twikoo_visitors"><i class="fa fa-spinner fa-spin"></i></span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">经典网络解读</h1><div class="content"><h2 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h2><h3 id="模型介绍"><a href="#模型介绍" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    LeNet-5是由$LeCun$ 提出的一种用于识别手写数字和机器印刷字符的卷积神经网络（Convolutional Neural Network，CNN）$^{[1]}$，其命名来源于作者$LeCun$的名字，5则是其研究成果的代号，在LeNet-5之前还有LeNet-4和LeNet-1鲜为人知。LeNet-5阐述了图像中像素特征之间的相关性能够由参数共享的卷积操作所提取，同时使用卷积、下采样（池化）和非线性映射这样的组合结构，是当前流行的大多数深度图像识别网络的基础。</p>
<a id="more"></a>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebi5531kj32rx0u07wi.jpg"></p>
<p>​                                                                 图4.1 LeNet-5网络结构图</p>
<p>​    如图4.1所示，LeNet-5一共包含7层（输入层不作为网络结构），分别由2个卷积层、2个下采样层和3个连接层组成，网络的参数配置如表4.1所示，其中下采样层和全连接层的核尺寸分别代表采样范围和连接矩阵的尺寸（如卷积核尺寸中的$“5\times5\times1/1,6”$表示核大小为$5\times5\times1$、步长为$1​$且核个数为6的卷积核）。</p>
<p>​                                                                 表4.1 LeNet-5网络参数配置</p>
<table>
<thead>
<tr>
<th align="center">网络层</th>
<th align="center">输入尺寸</th>
<th align="center">核尺寸</th>
<th align="center">输出尺寸</th>
<th align="center">可训练参数量</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积层$C_1$</td>
<td align="center">$32\times32\times1$</td>
<td align="center">$5\times5\times1/1,6$</td>
<td align="center">$28\times28\times6$</td>
<td align="center">$(5\times5\times1+1)\times6$</td>
</tr>
<tr>
<td align="center">下采样层$S_2$</td>
<td align="center">$28\times28\times6$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$14\times14\times6$</td>
<td align="center">$(1+1)\times6$ $^*$</td>
</tr>
<tr>
<td align="center">卷积层$C_3$</td>
<td align="center">$14\times14\times6$</td>
<td align="center">$5\times5\times6/1,16$</td>
<td align="center">$10\times10\times16$</td>
<td align="center">$1516^*$</td>
</tr>
<tr>
<td align="center">下采样层$S_4$</td>
<td align="center">$10\times10\times16$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$5\times5\times16$</td>
<td align="center">$(1+1)\times16$</td>
</tr>
<tr>
<td align="center">卷积层$C_5$$^*$</td>
<td align="center">$5\times5\times16$</td>
<td align="center">$5\times5\times16/1,120$</td>
<td align="center">$1\times1\times120$</td>
<td align="center">$(5\times5\times16+1)\times120$</td>
</tr>
<tr>
<td align="center">全连接层$F_6$</td>
<td align="center">$1\times1\times120$</td>
<td align="center">$120\times84$</td>
<td align="center">$1\times1\times84$</td>
<td align="center">$(120+1)\times84$</td>
</tr>
<tr>
<td align="center">输出层</td>
<td align="center">$1\times1\times84$</td>
<td align="center">$84\times10$</td>
<td align="center">$1\times1\times10$</td>
<td align="center">$(84+1)\times10$</td>
</tr>
</tbody></table>
<blockquote>
<p>​    $^*$ 在LeNet中，下采样操作和池化操作类似，但是在得到采样结果后会乘以一个系数和加上一个偏置项，所以下采样的参数个数是$(1+1)\times6​$而不是零。</p>
<p>​    $^*$ $C_3$卷积层可训练参数并未直接连接$S_2$中所有的特征图（Feature Map），而是采用如图4.2所示的采样特征方式进行连接（稀疏连接），生成的16个通道特征图中分别按照相邻3个特征图、相邻4个特征图、非相邻4个特征图和全部6个特征图进行映射，得到的参数个数计算公式为$6\times(25\times3+1)+6\times(25\times4+1)+3\times(25\times4+1)+1\times(25\times6+1)=1516$，在原论文中解释了使用这种采样方式原因包含两点：限制了连接数不至于过大（当年的计算能力比较弱）;强制限定不同特征图的组合可以使映射得到的特征图学习到不同的特征模式。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebiq3vr0j30du04l0td.jpg"></p>
<p>​                                                                图4.2 $S_2$与$C_3$之间的特征图稀疏连接</p>
<blockquote>
<p>​    $^*$ $C_5$卷积层在图4.1中显示为全连接层，原论文中解释这里实际采用的是卷积操作，只是刚好在$5\times5$卷积后尺寸被压缩为$1\times1​$，输出结果看起来和全连接很相似。</p>
</blockquote>
<h3 id="模型特性"><a href="#模型特性" class="headerlink" title="模型特性"></a>模型特性</h3><ul>
<li>卷积网络使用一个3层的序列组合：卷积、下采样（池化）、非线性映射（LeNet-5最重要的特性，奠定了目前深层卷积网络的基础）</li>
<li>使用卷积提取空间特征</li>
<li>使用映射的空间均值进行下采样</li>
<li>使用$tanh$或$sigmoid$进行非线性映射</li>
<li>多层神经网络（MLP）作为最终的分类器</li>
<li>层间的稀疏连接矩阵以避免巨大的计算开销</li>
</ul>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><h3 id="模型介绍-1"><a href="#模型介绍-1" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    AlexNet是由$Alex$ $Krizhevsky$提出的首个应用于图像分类的深层卷积神经网络，该网络在2012年ILSVRC（ImageNet Large Scale Visual Recognition Competition）图像分类竞赛中以15.3%的top-5测试错误率赢得第一名$^{[2]}$。AlexNet使用GPU代替CPU进行运算，使得在可接受的时间范围内模型结构能够更加复杂，它的出现证明了深层卷积神经网络在复杂模型下的有效性，使CNN在计算机视觉中流行开来，直接或间接地引发了深度学习的热潮。</p>
<h3 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebj74qa8j30pw0cwgo3.jpg"></p>
<p>​                                                                         图4.3 AlexNet网络结构图</p>
<p>​    如图4.3所示，除去下采样（池化层）和局部响应规范化操作（Local Responsible Normalization, LRN），AlexNet一共包含8层，前5层由卷积层组成，而剩下的3层为全连接层。网络结构分为上下两层，分别对应两个GPU的操作过程，除了中间某些层（$C_3$卷积层和$F_{6-8}$全连接层会有GPU间的交互），其他层两个GPU分别计算结 果。最后一层全连接层的输出作为$softmax$的输入，得到1000个图像分类标签对应的概率值。除去GPU并行结构的设计，AlexNet网络结构与LeNet十分相似，其网络的参数配置如表4.2所示。</p>
<p>​                                    表4.2 AlexNet网络参数配置</p>
<table>
<thead>
<tr>
<th align="center">网络层</th>
<th align="center">输入尺寸</th>
<th align="center">核尺寸</th>
<th align="center">输出尺寸</th>
<th align="center">可训练参数量</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积层$C_1$ $^*$</td>
<td align="center">$224\times224\times3$</td>
<td align="center">$11\times11\times3/4,48(\times2_{GPU})$</td>
<td align="center">$55\times55\times48(\times2_{GPU})$</td>
<td align="center">$(11\times11\times3+1)\times48\times2$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max}$$^*$</td>
<td align="center">$55\times55\times48(\times2_{GPU})$</td>
<td align="center">$3\times3/2(\times2_{GPU})$</td>
<td align="center">$27\times27\times48(\times2_{GPU})$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">卷积层$C_2$</td>
<td align="center">$27\times27\times48(\times2_{GPU})$</td>
<td align="center">$5\times5\times48/1,128(\times2_{GPU})$</td>
<td align="center">$27\times27\times128(\times2_{GPU})$</td>
<td align="center">$(5\times5\times48+1)\times128\times2$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max}$</td>
<td align="center">$27\times27\times128(\times2_{GPU})$</td>
<td align="center">$3\times3/2(\times2_{GPU})$</td>
<td align="center">$13\times13\times128(\times2_{GPU})$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">卷积层$C_3$ $^*$</td>
<td align="center">$13\times13\times128\times2_{GPU}$</td>
<td align="center">$3\times3\times256/1,192(\times2_{GPU})$</td>
<td align="center">$13\times13\times192(\times2_{GPU})$</td>
<td align="center">$(3\times3\times256+1)\times192\times2$</td>
</tr>
<tr>
<td align="center">卷积层$C_4$</td>
<td align="center">$13\times13\times192(\times2_{GPU})$</td>
<td align="center">$3\times3\times192/1,192(\times2_{GPU})$</td>
<td align="center">$13\times13\times192(\times2_{GPU})$</td>
<td align="center">$(3\times3\times192+1)\times192\times2$</td>
</tr>
<tr>
<td align="center">卷积层$C_5$</td>
<td align="center">$13\times13\times192(\times2_{GPU})$</td>
<td align="center">$3\times3\times192/1,128(\times2_{GPU})$</td>
<td align="center">$13\times13\times128(\times2_{GPU})$</td>
<td align="center">$(3\times3\times192+1)\times128\times2$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max}$</td>
<td align="center">$13\times13\times128(\times2_{GPU})$</td>
<td align="center">$3\times3/2(\times2_{GPU})$</td>
<td align="center">$6\times6\times128(\times2_{GPU})$</td>
<td align="center">0</td>
</tr>
<tr>
<td align="center">全连接层$F_6$  $^*$</td>
<td align="center">$6\times6\times128\times2_{GPU}$</td>
<td align="center">$9216\times2048(\times2_{GPU})$</td>
<td align="center">$1\times1\times2048(\times2_{GPU})$</td>
<td align="center">$(9216+1)\times2048\times2$</td>
</tr>
<tr>
<td align="center">全连接层$F_7$</td>
<td align="center">$1\times1\times2048\times2_{GPU}$</td>
<td align="center">$4096\times2048(\times2_{GPU})$</td>
<td align="center">$1\times1\times2048(\times2_{GPU})$</td>
<td align="center">$(4096+1)\times2048\times2$</td>
</tr>
<tr>
<td align="center">全连接层$F_8$</td>
<td align="center">$1\times1\times2048\times2_{GPU}$</td>
<td align="center">$4096\times1000$</td>
<td align="center">$1\times1\times1000$</td>
<td align="center">$(4096+1)\times1000\times2$</td>
</tr>
</tbody></table>
<blockquote>
<p>卷积层$C_1$输入为$224\times224\times3$的图片数据，分别在两个GPU中经过核为$11\times11\times3$、步长（stride）为4的卷积卷积后，分别得到两条独立的$55\times55\times48$的输出数据。</p>
<p>下采样层$v$实际上是嵌套在卷积中的最大池化操作，但是为了区分没有采用最大池化的卷积层单独列出来。在$C_{1-2}$卷积层中的池化操作之后（ReLU激活操作之前），还有一个LRN操作，用作对相邻特征点的归一化处理。</p>
<p>卷积层$C_3$的输入与其他卷积层不同，$13\times13\times192\times2_{GPU}$表示汇聚了上一层网络在两个GPU上的输出结果作为输入，所以在进行卷积操作时通道上的卷积核维度为384。</p>
<p>全连接层$F_{6-8}$中输入数据尺寸也和$C_3$类似，都是融合了两个GPU流向的输出结果作为输入。</p>
</blockquote>
<h3 id="模型特性-1"><a href="#模型特性-1" class="headerlink" title="模型特性"></a>模型特性</h3><ul>
<li>所有卷积层都使用ReLU作为非线性映射函数，使模型收敛速度更快</li>
<li>在多个GPU上进行模型的训练，不但可以提高模型的训练速度，还能提升数据的使用规模</li>
<li>使用LRN对局部的特征进行归一化，结果作为ReLU激活函数的输入能有效降低错误率</li>
<li>重叠最大池化（overlapping max pooling），即池化范围z与步长s存在关系$z&gt;s$（如$S_{max}$中核尺度为$3\times3/2$），避免平均池化（average pooling）的平均效应</li>
<li>使用随机丢弃技术（dropout）选择性地忽略训练中的单个神经元，避免模型的过拟合</li>
</ul>
<h2 id="ZFNet"><a href="#ZFNet" class="headerlink" title="ZFNet"></a>ZFNet</h2><h3 id="模型介绍-2"><a href="#模型介绍-2" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    ZFNet是由$Matthew$ $D. Zeiler$和$Rob$ $Fergus$在AlexNet基础上提出的大型卷积网络，在2013年ILSVRC图像分类竞赛中以11.19%的错误率获得冠军（实际上原ZFNet所在的队伍并不是真正的冠军，原ZFNet以13.51%错误率排在第8，真正的冠军是$Clarifai$这个队伍，而$Clarifai$这个队伍所对应的一家初创公司的CEO又是$Zeiler$，而且$Clarifai$对ZFNet的改动比较小，所以通常认为是ZFNet获得了冠军）$^{[3-4]}​$。ZFNet实际上是微调（fine-tuning）了的AlexNet，并通过反卷积（Deconvolution）的方式可视化各层的输出特征图，进一步解释了卷积操作在大型网络中效果显著的原因。</p>
<h3 id="模型结构-2"><a href="#模型结构-2" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebjy8o5ej339v0u0b29.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebk63lrrj30pw094wfw.jpg"></p>
<p>​                        图4.4 ZFNet网络结构图（原始结构图与AlexNet风格结构图）</p>
<p>​    如图4.4所示，ZFNet与AlexNet类似，都是由8层网络组成的卷积神经网络，其中包含5层卷积层和3层全连接层。两个网络结构最大的不同在于，ZFNet第一层卷积采用了$7\times7\times3/2$的卷积核替代了AlexNet中第一层卷积核$11\times11\times3/4$的卷积核。图4.5中ZFNet相比于AlexNet在第一层输出的特征图中包含更多中间频率的信息，而AlexNet第一层输出的特征图大多是低频或高频的信息，对中间频率特征的缺失导致后续网络层次如图4.5（c）能够学习到的特征不够细致，而导致这个问题的根本原因在于AlexNet在第一层中采用的卷积核和步长过大。</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkda5gmj309a03vt94.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebkkk3gkj30ez04mdgk.jpg"></p>
<p>​    图4.5 （a）ZFNet第一层输出的特征图（b）AlexNet第一层输出的特征图（c）AlexNet第二层输出的特征图（d）ZFNet第二层输出的特征图</p>
<p>​                                    表4.3 ZFNet网络参数配置<br>​<br>|        网络层         |               输入尺寸               |                  核尺寸                  |               输出尺寸               |              可训练参数量               |<br>| :——————-: | :———————————-: | :————————————–: | :———————————-: | :————————————-: |<br>|   卷积层$C_1$ $^*$  |        $224\times224\times3$         |          $7\times7\times3/2,96$          |        $110\times110\times96$        |      $(7\times7\times3+1)\times96$      |<br>| 下采样层$S_{max}$ |        $110\times110\times96$        |               $3\times3/2$               |         $55\times55\times96$         |                    0                    |<br>|      卷积层$C_2$ $^*$      |         $55\times55\times96$         |         $5\times5\times96/2,256$         |        $26\times26\times256$        | $(5\times5\times96+1)\times256$ |<br>|   下采样层$S_{max}$   | $26\times26\times256$ |       $3\times3/2$       | $13\times13\times256$ |                    0                    |<br>|   卷积层$C_3$  |  $13\times13\times256$  | $3\times3\times256/1,384$ | $13\times13\times384$ | $(3\times3\times256+1)\times384$ |<br>|      卷积层$C_4$      | $13\times13\times384$ | $3\times3\times384/1,384$ | $13\times13\times384$ | $(3\times3\times384+1)\times384$ |<br>|      卷积层$C_5$      | $13\times13\times384$ | $3\times3\times384/1,256$ | $13\times13\times256$ | $(3\times3\times384+1)\times256$ |<br>|   下采样层$S_{max}$   | $13\times13\times256$ |       $3\times3/2$       |  $6\times6\times256$  |                    0                    |<br>|  全连接层$F_6$  |   $6\times6\times256$   |     $9216\times4096$     | $1\times1\times4096$ |       $(9216+1)\times4096$       |<br>|     全连接层$F_7$     |  $1\times1\times4096$  |     $4096\times4096$     | $1\times1\times4096$ |       $(4096+1)\times4096$       |<br>|     全连接层$F_8$     | $1\times1\times4096$ |             $4096\times1000$             |         $1\times1\times1000$         |       $(4096+1)\times1000$       |</p>
<blockquote>
<p>卷积层$C_1$与AlexNet中的$C_1$有所不同，采用$7\times7\times3/2$的卷积核代替$11\times11\times3/4​$，使第一层卷积输出的结果可以包含更多的中频率特征，对后续网络层中多样化的特征组合提供更多选择，有利于捕捉更细致的特征。</p>
<p>卷积层$C_2$采用了步长2的卷积核，区别于AlexNet中$C_2$的卷积核步长，所以输出的维度有所差异。</p>
</blockquote>
<h3 id="模型特性-2"><a href="#模型特性-2" class="headerlink" title="模型特性"></a>模型特性</h3><p>​    ZFNet与AlexNet在结构上几乎相同，此部分虽属于模型特性，但准确地说应该是ZFNet原论文中可视化技术的贡献。</p>
<ul>
<li>可视化技术揭露了激发模型中每层单独的特征图。</li>
<li>可视化技术允许观察在训练阶段特征的演变过程且诊断出模型的潜在问题。</li>
<li>可视化技术用到了多层解卷积网络，即由特征激活返回到输入像素空间。</li>
<li>可视化技术进行了分类器输出的敏感性分析，即通过阻止部分输入图像来揭示那部分对于分类是重要的。</li>
<li>可视化技术提供了一个非参数的不变性来展示来自训练集的哪一块激活哪个特征图，不仅需要裁剪输入图片，而且自上而下的投影来揭露来自每块的结构激活一个特征图。</li>
<li>可视化技术依赖于解卷积操作，即卷积操作的逆过程，将特征映射到像素上。</li>
</ul>
<h2 id="Network-in-Network"><a href="#Network-in-Network" class="headerlink" title="Network in Network"></a>Network in Network</h2><h3 id="模型介绍-3"><a href="#模型介绍-3" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    Network In Network (NIN)是由$Min Lin$等人提出，在CIFAR-10和CIFAR-100分类任务中达到当时的最好水平，因其网络结构是由三个多层感知机堆叠而被成为NIN$^{[5]}$。NIN以一种全新的角度审视了卷积神经网络中的卷积核设计，通过引入子网络结构代替纯卷积中的线性映射部分，这种形式的网络结构激发了更复杂的卷积神经网络的结构设计，其中下一节中介绍的GoogLeNet的Inception结构就是来源于这个思想。</p>
<h3 id="模型结构-3"><a href="#模型结构-3" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebl3ag0gj32yn0u01ky.jpg"><br>​                                    图 4.6 NIN网络结构图</p>
<p>​    NIN由三层的多层感知卷积层（MLPConv Layer）构成，每一层多层感知卷积层内部由若干层的局部全连接层和非线性激活函数组成，代替了传统卷积层中采用的线性卷积核。在网络推理（inference）时，这个多层感知器会对输入特征图的局部特征进行划窗计算，并且每个划窗的局部特征图对应的乘积的权重是共享的，这两点是和传统卷积操作完全一致的，最大的不同在于多层感知器对局部特征进行了非线性的映射，而传统卷积的方式是线性的。NIN的网络参数配置表4.4所示（原论文并未给出网络参数，表中参数为编者结合网络结构图和CIFAR-100数据集以$3\times3$卷积为例给出）。</p>
<p>​                    表4.4 NIN网络参数配置（结合原论文NIN结构和CIFAR-100数据给出）</p>
<table>
<thead>
<tr>
<th align="center">网络层</th>
<th align="center">输入尺寸</th>
<th align="center">核尺寸</th>
<th align="center">输出尺寸</th>
<th align="center">参数个数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">局部全连接层$L_{11}$ $^*$</td>
<td align="center">$32\times32\times3$</td>
<td align="center">$(3\times3)\times16/1$</td>
<td align="center">$30\times30\times16$</td>
<td align="center">$(3\times3\times3+1)\times16$</td>
</tr>
<tr>
<td align="center">全连接层$L_{12}$ $^*$</td>
<td align="center">$30\times30\times16$</td>
<td align="center">$16\times16$</td>
<td align="center">$30\times30\times16$</td>
<td align="center">$((16+1)\times16)$</td>
</tr>
<tr>
<td align="center">局部全连接层$L_{21}$</td>
<td align="center">$30\times30\times16$</td>
<td align="center">$(3\times3)\times64/1$</td>
<td align="center">$28\times28\times64$</td>
<td align="center">$(3\times3\times16+1)\times64$</td>
</tr>
<tr>
<td align="center">全连接层$L_{22}$</td>
<td align="center">$28\times28\times64$</td>
<td align="center">$64\times64$</td>
<td align="center">$28\times28\times64$</td>
<td align="center">$((64+1)\times64)$</td>
</tr>
<tr>
<td align="center">局部全连接层$L_{31}$</td>
<td align="center">$28\times28\times64$</td>
<td align="center">$(3\times3)\times100/1$</td>
<td align="center">$26\times26\times100$</td>
<td align="center">$(3\times3\times64+1)\times100$</td>
</tr>
<tr>
<td align="center">全连接层$L_{32}$</td>
<td align="center">$26\times26\times100$</td>
<td align="center">$100\times100$</td>
<td align="center">$26\times26\times100$</td>
<td align="center">$((100+1)\times100)$</td>
</tr>
<tr>
<td align="center">全局平均采样$GAP$ $^*$</td>
<td align="center">$26\times26\times100$</td>
<td align="center">$26\times26\times100/1$</td>
<td align="center">$1\times1\times100$</td>
<td align="center">$0$</td>
</tr>
</tbody></table>
<blockquote>
<p>局部全连接层$L_{11}$实际上是对原始输入图像进行划窗式的全连接操作，因此划窗得到的输出特征尺寸为$30\times30$（$\frac{32-3_k+1}{1_{stride}}=30$）<br>全连接层$L_{12}$是紧跟$L_{11}$后的全连接操作，输入的特征是划窗后经过激活的局部响应特征，因此仅需连接$L_{11}$和$L_{12}$的节点即可，而每个局部全连接层和紧接的全连接层构成代替卷积操作的多层感知卷积层（MLPConv）。<br>全局平均采样层或全局平均池化层$GAP$（Global Average Pooling）将$L_{32}$输出的每一个特征图进行全局的平均池化操作，直接得到最后的类别数，可以有效地减少参数量。</p>
</blockquote>
<h3 id="模型特点"><a href="#模型特点" class="headerlink" title="模型特点"></a>模型特点</h3><ul>
<li>使用多层感知机结构来代替卷积的滤波操作，不但有效减少卷积核数过多而导致的参数量暴涨问题，还能通过引入非线性的映射来提高模型对特征的抽象能力。</li>
<li>使用全局平均池化来代替最后一个全连接层，能够有效地减少参数量（没有可训练参数），同时池化用到了整个特征图的信息，对空间信息的转换更加鲁棒，最后得到的输出结果可直接作为对应类别的置信度。</li>
</ul>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><h3 id="模型介绍-4"><a href="#模型介绍-4" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    VGGNet是由牛津大学视觉几何小组（Visual Geometry Group, VGG）提出的一种深层卷积网络结构，他们以7.32%的错误率赢得了2014年ILSVRC分类任务的亚军（冠军由GoogLeNet以6.65%的错误率夺得）和25.32%的错误率夺得定位任务（Localization）的第一名（GoogLeNet错误率为26.44%）$^{[5]}$，网络名称VGGNet取自该小组名缩写。VGGNet是首批把图像分类的错误率降低到10%以内模型，同时该网络所采用的$3\times3$卷积核的思想是后来许多模型的基础，该模型发表在2015年国际学习表征会议（International Conference On Learning Representations, ICLR）后至今被引用的次数已经超过1万4千余次。</p>
<h3 id="模型结构-4"><a href="#模型结构-4" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8eblp18bwj30d207odge.jpg"></p>
<p>​                                图 4.7 VGG16网络结构图</p>
<p>​    在原论文中的VGGNet包含了6个版本的演进，分别对应VGG11、VGG11-LRN、VGG13、VGG16-1、VGG16-3和VGG19，不同的后缀数值表示不同的网络层数（VGG11-LRN表示在第一层中采用了LRN的VGG11，VGG16-1表示后三组卷积块中最后一层卷积采用卷积核尺寸为$1\times1$，相应的VGG16-3表示卷积核尺寸为$3\times3$），本节介绍的VGG16为VGG16-3。图4.7中的VGG16体现了VGGNet的核心思路，使用$3\times3$的卷积组合代替大尺寸的卷积（2个$3\times3卷积即可与$$5\times5$卷积拥有相同的感受视野），网络参数设置如表4.5所示。</p>
<p>​                                表4.5 VGG16网络参数配置</p>
<table>
<thead>
<tr>
<th align="center">网络层</th>
<th align="center">输入尺寸</th>
<th align="center">核尺寸</th>
<th align="center">输出尺寸</th>
<th align="center">参数个数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积层$C_{11}$</td>
<td align="center">$224\times224\times3$</td>
<td align="center">$3\times3\times64/1$</td>
<td align="center">$224\times224\times64$</td>
<td align="center">$(3\times3\times3+1)\times64$</td>
</tr>
<tr>
<td align="center">卷积层$C_{12}$</td>
<td align="center">$224\times224\times64$</td>
<td align="center">$3\times3\times64/1$</td>
<td align="center">$224\times224\times64$</td>
<td align="center">$(3\times3\times64+1)\times64$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max1}$</td>
<td align="center">$224\times224\times64$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$112\times112\times64$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">卷积层$C_{21}$</td>
<td align="center">$112\times112\times64$</td>
<td align="center">$3\times3\times128/1$</td>
<td align="center">$112\times112\times128$</td>
<td align="center">$(3\times3\times64+1)\times128$</td>
</tr>
<tr>
<td align="center">卷积层$C_{22}$</td>
<td align="center">$112\times112\times128$</td>
<td align="center">$3\times3\times128/1$</td>
<td align="center">$112\times112\times128$</td>
<td align="center">$(3\times3\times128+1)\times128$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max2}$</td>
<td align="center">$112\times112\times128$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$56\times56\times128$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">卷积层$C_{31}$</td>
<td align="center">$56\times56\times128$</td>
<td align="center">$3\times3\times256/1$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$(3\times3\times128+1)\times256$</td>
</tr>
<tr>
<td align="center">卷积层$C_{32}$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$3\times3\times256/1$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$(3\times3\times256+1)\times256$</td>
</tr>
<tr>
<td align="center">卷积层$C_{33}$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$3\times3\times256/1$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$(3\times3\times256+1)\times256$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max3}$</td>
<td align="center">$56\times56\times256$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$28\times28\times256$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">卷积层$C_{41}$</td>
<td align="center">$28\times28\times256$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$(3\times3\times256+1)\times512$</td>
</tr>
<tr>
<td align="center">卷积层$C_{42}$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td align="center">卷积层$C_{43}$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max4}$</td>
<td align="center">$28\times28\times512$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">卷积层$C_{51}$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td align="center">卷积层$C_{52}$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td align="center">卷积层$C_{53}$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$3\times3\times512/1$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$(3\times3\times512+1)\times512$</td>
</tr>
<tr>
<td align="center">下采样层$S_{max5}$</td>
<td align="center">$14\times14\times512$</td>
<td align="center">$2\times2/2$</td>
<td align="center">$7\times7\times512$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">全连接层$FC_{1}$</td>
<td align="center">$7\times7\times512$</td>
<td align="center">$(7\times7\times512)\times4096$</td>
<td align="center">$1\times4096$</td>
<td align="center">$(7\times7\times512+1)\times4096$</td>
</tr>
<tr>
<td align="center">全连接层$FC_{2}$</td>
<td align="center">$1\times4096$</td>
<td align="center">$4096\times4096$</td>
<td align="center">$1\times4096$</td>
<td align="center">$(4096+1)\times4096$</td>
</tr>
<tr>
<td align="center">全连接层$FC_{3}$</td>
<td align="center">$1\times4096$</td>
<td align="center">$4096\times1000$</td>
<td align="center">$1\times1000$</td>
<td align="center">$(4096+1)\times1000$</td>
</tr>
</tbody></table>
<h3 id="模型特性-3"><a href="#模型特性-3" class="headerlink" title="模型特性"></a>模型特性</h3><ul>
<li>整个网络都使用了同样大小的卷积核尺寸$3\times3$和最大池化尺寸$2\times2$。</li>
<li>$1\times1$卷积的意义主要在于线性变换，而输入通道数和输出通道数不变，没有发生降维。</li>
<li>两个$3\times3$的卷积层串联相当于1个$5\times5$的卷积层，感受野大小为$5\times5$。同样地，3个$3\times3$的卷积层串联的效果则相当于1个$7\times7$的卷积层。这样的连接方式使得网络参数量更小，而且多层的激活函数令网络对特征的学习能力更强。</li>
<li>VGGNet在训练时有一个小技巧，先训练浅层的的简单网络VGG11，再复用VGG11的权重来初始化VGG13，如此反复训练并初始化VGG19，能够使训练时收敛的速度更快。</li>
<li>在训练过程中使用多尺度的变换对原始数据做数据增强，使得模型不易过拟合。</li>
</ul>
<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><h3 id="模型介绍-5"><a href="#模型介绍-5" class="headerlink" title="模型介绍"></a>模型介绍</h3><p>​    GoogLeNet作为2014年ILSVRC在分类任务上的冠军，以6.65%的错误率力压VGGNet等模型，在分类的准确率上面相比过去两届冠军ZFNet和AlexNet都有很大的提升。从名字<strong>GoogLe</strong>Net可以知道这是来自谷歌工程师所设计的网络结构，而名字中Goog<strong>LeNet</strong>更是致敬了LeNet$^{[0]}$。GoogLeNet中最核心的部分是其内部子网络结构Inception，该结构灵感来源于NIN，至今已经经历了四次版本迭代（Inception$_{v1-4}$）。</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebm42jyij30ic0d4jt6.jpg"><br>​                    图 4.8 Inception性能比较图</p>
<h3 id="模型结构-5"><a href="#模型结构-5" class="headerlink" title="模型结构"></a>模型结构</h3><p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebnslykaj30zi0hu0vd.jpg"><br>​                    图 4.9 GoogLeNet网络结构图<br>​    如图4.9中所示，GoogLeNet相比于以前的卷积神经网络结构，除了在深度上进行了延伸，还对网络的宽度进行了扩展，整个网络由许多块状子网络的堆叠而成，这个子网络构成了Inception结构。图4.9为Inception的四个版本：$Inception_{v1}​$在同一层中采用不同的卷积核，并对卷积结果进行合并;$Inception_{v2}​$组合不同卷积核的堆叠形式，并对卷积结果进行合并;$Inception_{v3}​$则在$v_2​$基础上进行深度组合的尝试;$Inception_{v4}​$结构相比于前面的版本更加复杂，子网络中嵌套着子网络。</p>
<p>$Inception_{v1}$</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8eboig32aj30lc0bvjsb.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebp5bpf8j31690u00yz.jpg"></p>
<p>$Inception_{v2}$</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebpn1fxkj30ez0ebq3l.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebq7rn4mj30ey0fpmxy.jpg"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebqp08eqj30lr0g9myd.jpg"></p>
<p>$Inception_{v3}$</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebr0kw83j306s0d7aah.jpg"></p>
<p>$Inception_{v4}$</p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebrnp4g3j30an0vo0ui.jpg"></p>
<p><img src="../images/image47.png"></p>
<p><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8ebv0xlahj30960obwfw.jpg"></p>
<p>​                    图 4.10 Inception$_{v1-4}$结构图</p>
<p>​                    表 4.6 GoogLeNet中Inception$_{v1}$网络参数配置</p>
<table>
<thead>
<tr>
<th align="center">网络层</th>
<th align="center">输入尺寸</th>
<th align="center">核尺寸</th>
<th align="center">输出尺寸</th>
<th align="center">参数个数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积层$C_{11}$</td>
<td align="center">$H\times{W}\times{C_1}$</td>
<td align="center">$1\times1\times{C_2}/2$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$(1\times1\times{C_1}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">卷积层$C_{21}$</td>
<td align="center">$H\times{W}\times{C_2}$</td>
<td align="center">$1\times1\times{C_2}/2$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$(1\times1\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">卷积层$C_{22}$</td>
<td align="center">$H\times{W}\times{C_2}$</td>
<td align="center">$3\times3\times{C_2}/1$</td>
<td align="center">$H\times{W}\times{C_2}/1$</td>
<td align="center">$(3\times3\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">卷积层$C_{31}$</td>
<td align="center">$H\times{W}\times{C_1}$</td>
<td align="center">$1\times1\times{C_2}/2$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$(1\times1\times{C_1}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">卷积层$C_{32}$</td>
<td align="center">$H\times{W}\times{C_2}$</td>
<td align="center">$5\times5\times{C_2}/1$</td>
<td align="center">$H\times{W}\times{C_2}/1$</td>
<td align="center">$(5\times5\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">下采样层$S_{41}$</td>
<td align="center">$H\times{W}\times{C_1}$</td>
<td align="center">$3\times3/2$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$0$</td>
</tr>
<tr>
<td align="center">卷积层$C_{42}$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$1\times1\times{C_2}/1$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}$</td>
<td align="center">$(3\times3\times{C_2}+1)\times{C_2}$</td>
</tr>
<tr>
<td align="center">合并层$M$</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times{C_2}(\times4)$</td>
<td align="center">拼接</td>
<td align="center">$\frac{H}{2}\times\frac{W}{2}\times({C_2}\times4)$</td>
<td align="center">$0$</td>
</tr>
</tbody></table>
<h3 id="模型特性-4"><a href="#模型特性-4" class="headerlink" title="模型特性"></a>模型特性</h3><ul>
<li><p>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； </p>
</li>
<li><p>之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；</p>
</li>
<li><p>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN2，采用1x1卷积核来进行降维。</p>
</li>
</ul>
<h2 id="为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？"><a href="#为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？" class="headerlink" title="为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？"></a>为什么现在的CNN模型都是在GoogleNet、VGGNet或者AlexNet上调整的？</h2><ul>
<li>评测对比：为了让自己的结果更有说服力，在发表自己成果的时候会同一个标准的baseline及在baseline上改进而进行比较，常见的比如各种检测分割的问题都会基于VGG或者Resnet101这样的基础网络。</li>
<li>时间和精力有限：在科研压力和工作压力中，时间和精力只允许大家在有限的范围探索。</li>
<li>模型创新难度大：进行基本模型的改进需要大量的实验和尝试，并且需要大量的实验积累和强大灵感，很有可能投入产出比比较小。</li>
<li>资源限制：创造一个新的模型需要大量的时间和计算资源，往往在学校和小型商业团队不可行。</li>
<li>在实际的应用场景中，其实是有大量的非标准模型的配置。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. <em>Proceedings of the IEEE</em>, november 1998.</p>
<p>[2] A. Krizhevsky, I. Sutskever and G. E. Hinton. ImageNet Classification with Deep Convolutional Neural Networks. <em>Advances in Neural Information Processing Systems 25</em>. Curran Associates, Inc. 1097–1105.</p>
<p>[3] LSVRC-2013. <a target="_blank" rel="noopener" href="http://www.image-net.org/challenges/LSVRC/2013/results.php">http://www.image-net.org/challenges/LSVRC/2013/results.php</a></p>
<p>[4] M. D. Zeiler and R. Fergus. Visualizing and Understanding Convolutional Networks. <em>European Conference on Computer Vision</em>. </p>
<p>[5] M. Lin,  Q. Chen,  and S. Yan.   Network in network. <em>Computing Research Repository</em>, abs/1312.4400, 2013.</p>
<p>[6] K. Simonyan and A. Zisserman.  Very Deep Convolutional Networks for Large-Scale Image Recognition. <em>International Conference on Machine Learning</em>, 2015.</p>
<p>[7] Bharath Raj. <a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202">a-simple-guide-to-the-versions-of-the-inception-network</a>, 2018.</p>
<p>[8] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1602.07261.pdf">Inception-v4, Inception-ResNet and<br>the Impact of Residual Connections on Learning</a>, 2016.</p>
<p>[9] Sik-Ho Tsang. <a target="_blank" rel="noopener" href="https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc">review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification</a>, 2018.</p>
<p>[10] Zbigniew Wojna, Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.00567v3.pdf">Rethinking the Inception Architecture for Computer Vision</a>, 2015.</p>
<p>[11] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1409.4842v1.pdf">Going deeper with convolutions</a>, 2014.</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>经典网络解读</p><p><a href="https://huzhiliang.com/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/">https://huzhiliang.com/2019/10/28/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C%E8%A7%A3%E8%AF%BB/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-10-28</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2019-10-29</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/">经典网络</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><div class="card"><nav class="post-navigation mt-4 level is-mobile card-content"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/10/29/First-Position-of-Target/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">First Position of Target</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/10/28/Find-Peak-Element/"><span class="level-item">Find Peak Element</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">161</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">97</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener" id="widget-follow">微博 Weibo</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div><a class="link-more button is-light is-small size-small" href="/friends/">查看更多</a></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Golang/"><span class="level-start"><span class="level-item">Golang</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/LeetCode/"><span class="level-start"><span class="level-item">LeetCode</span></span><span class="level-end"><span class="level-item tag">85</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="level-start"><span class="level-item">数据结构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">29</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"><span class="level-start"><span class="level-item">CNN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">迁移学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%A0%B4%E8%A7%A3/"><span class="level-start"><span class="level-item">破解</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">英语学习</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-05T05:41:28.000Z">2020-03-05</time></p><p class="title"><a href="/2020/03/05/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%89-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E8%A7%A3%E7%A0%81/">条件随机场CRF(三) 模型学习与维特比算法解码</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-04T08:24:55.000Z">2020-03-04</time></p><p class="title"><a href="/2020/03/04/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%BA%8C-%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A0%87%E8%AE%B0%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87/">条件随机场CRF(二) 前向后向算法评估标记序列概率</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-03T02:59:49.000Z">2020-03-03</time></p><p class="title"><a href="/2020/03/03/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%80-%E4%BB%8E%E9%9A%8F%E6%9C%BA%E5%9C%BA%E5%88%B0%E7%BA%BF%E6%80%A7%E9%93%BE%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">条件随机场CRF(一)从随机场到线性链条件随机场</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-02T02:46:01.000Z">2020-03-02</time></p><p class="title"><a href="/2020/03/02/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E7%9A%84%E5%88%86%E8%AF%8D%E5%8E%9F%E7%90%86/">文本挖掘的分词原理</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-02-20T01:01:00.000Z">2020-02-20</time></p><p class="title"><a href="/2020/02/20/optimize-water-distribution-in-a-village/">optimize water distribution in a village</a></p><p class="categories"><a href="/categories/LeetCode/">LeetCode</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">一月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">十二月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">十一月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">九月 2019</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">七月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">八月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/02/"><span class="level-start"><span class="level-item">二月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/01/"><span class="level-start"><span class="level-item">一月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/12/"><span class="level-start"><span class="level-item">十二月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/11/"><span class="level-start"><span class="level-item">十一月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/10/"><span class="level-start"><span class="level-item">十月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/09/"><span class="level-start"><span class="level-item">九月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/07/"><span class="level-start"><span class="level-item">七月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/06/"><span class="level-start"><span class="level-item">六月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/05/"><span class="level-start"><span class="level-item">五月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/03/"><span class="level-start"><span class="level-item">三月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/02/"><span class="level-start"><span class="level-item">二月 2017</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/04/"><span class="level-start"><span class="level-item">四月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/02/"><span class="level-start"><span class="level-item">二月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CFG/"><span class="tag">CFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CYK/"><span class="tag">CYK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Caffee/"><span class="tag">Caffee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English/"><span class="tag">English</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Facebook/"><span class="tag">Facebook</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GBDT/"><span class="tag">GBDT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPU/"><span class="tag">GPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GRN/"><span class="tag">GRN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GloVe/"><span class="tag">GloVe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Google-apac/"><span class="tag">Google apac</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go%E8%AF%AD%E8%A8%80/"><span class="tag">Go语言</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Greedy/"><span class="tag">Greedy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HMM/"><span class="tag">HMM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IBM-Modes/"><span class="tag">IBM Modes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL%E6%95%A3%E5%BA%A6/"><span class="tag">KL散度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LeetCode/"><span class="tag">LeetCode</span><span class="tag">31</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexicalized-PCFG/"><span class="tag">Lexicalized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexized-PCFG/"><span class="tag">Lexized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Linear-Models/"><span class="tag">Log-Linear Models</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PCFG/"><span class="tag">PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Programmer/"><span class="tag">Programmer</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Queue/"><span class="tag">Queue</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Seq2seq/"><span class="tag">Seq2seq</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tagging/"><span class="tag">Tagging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tencent/"><span class="tag">Tencent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VIP/"><span class="tag">VIP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Viterbi/"><span class="tag">Viterbi</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-representation/"><span class="tag">Word representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XGBoost/"><span class="tag">XGBoost</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/exhaustive-search/"><span class="tag">exhaustive search</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/turtle/"><span class="tag">turtle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%93%E9%A2%98/"><span class="tag">专题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"><span class="tag">二分搜索</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91/"><span class="tag">二分搜索树</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%A0%91/"><span class="tag">二分树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"><span class="tag">二进制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"><span class="tag">优化算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E7%B1%BB/"><span class="tag">分类</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E8%AF%8D/"><span class="tag">分词</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%91%E6%8C%87offer/"><span class="tag">剑指offer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E5%9B%9E%E5%BD%92/"><span class="tag">动态回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"><span class="tag">动态规划</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%9E%E5%BD%92/"><span class="tag">回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E8%AE%BA/"><span class="tag">图论</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F/"><span class="tag">排序</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"><span class="tag">数学原理</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="tag">数据分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"><span class="tag">条件随机场</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6/"><span class="tag">极大似然</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"><span class="tag">模型压缩</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/"><span class="tag">模型部署</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%88%E6%9D%83/"><span class="tag">版权</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/"><span class="tag">特征抽取</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"><span class="tag">算法原理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/"><span class="tag">算法复杂度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">线性模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%84%E5%90%88%E6%A0%91/"><span class="tag">组合树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"><span class="tag">经典网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"><span class="tag">统计机器翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90/"><span class="tag">网易云音乐</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%81%9A%E7%B1%BB/"><span class="tag">聚类</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"><span class="tag">背包问题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%84%9A%E6%9C%AC/"><span class="tag">脚本</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E6%B3%95/"><span class="tag">语法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><span class="tag">语言模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4/"><span class="tag">超参数调整</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="tag">迁移学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%92%E5%BD%92/"><span class="tag">递归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%82%AE%E4%BB%B6/"><span class="tag">邮件</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%93%BE%E8%A1%A8/"><span class="tag">链表</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%99%8D%E7%BB%B4/"><span class="tag">降维</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95%E4%B8%93%E5%9C%BA/"><span class="tag">面试专场</span><span class="tag">2</span></a></div></div></div></div></div><div class="card widget" id="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2020 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><a href="http://www.miitbeian.gov.cn" target="_blank">豫ICP备18017229号</a> - </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/live2d/autoload.js"></script></body></html>