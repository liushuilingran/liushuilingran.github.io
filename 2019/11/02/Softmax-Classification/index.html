<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Softmax Classification - MCFON</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="MCFON"><meta name="msapplication-TileImage" content="/images/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="MCFON"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="什么是softmax对于一个输入$x$, 我们想知道它是N个类别中的哪一类假设我们有一个模型，能对输入x输出N个类别的评分，评分越高说明x是这个类别的可能性越大，评分最高的被认为是$x$正确的类别。"><meta property="og:type" content="blog"><meta property="og:title" content="Softmax Classification"><meta property="og:url" content="https://huzhiliang.com/2019/11/02/Softmax-Classification/"><meta property="og:site_name" content="MCFON"><meta property="og:description" content="什么是softmax对于一个输入$x$, 我们想知道它是N个类别中的哪一类假设我们有一个模型，能对输入x输出N个类别的评分，评分越高说明x是这个类别的可能性越大，评分最高的被认为是$x$正确的类别。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jb2anttyj31hm0rw40z.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbd3ayqfj30kg0fmgnb.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbnt2b1yj31800cq0up.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg"><meta property="og:image" content="https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg"><meta property="article:published_time" content="2019-11-01T22:29:44.000Z"><meta property="article:modified_time" content="2020-03-05T05:03:58.184Z"><meta property="article:author" content="ฅ´ω`ฅ"><meta property="article:tag" content="分类"><meta property="article:tag" content="极大似然"><meta property="article:tag" content="KL散度"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jb2anttyj31hm0rw40z.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://huzhiliang.com/2019/11/02/Softmax-Classification/"},"headline":"MCFON","image":["https://tva1.sinaimg.cn/large/006y8mN6gy1g8jb2anttyj31hm0rw40z.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbd3ayqfj30kg0fmgnb.jpg","https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbnt2b1yj31800cq0up.jpg","https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg","https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg"],"datePublished":"2019-11-01T22:29:44.000Z","dateModified":"2020-03-05T05:03:58.184Z","author":{"@type":"Person","name":"ฅ´ω`ฅ"},"description":"什么是softmax对于一个输入$x$, 我们想知道它是N个类别中的哪一类假设我们有一个模型，能对输入x输出N个类别的评分，评分越高说明x是这个类别的可能性越大，评分最高的被认为是$x$正确的类别。"}</script><link rel="canonical" href="https://huzhiliang.com/2019/11/02/Softmax-Classification/"><link rel="icon" href="/images/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.3.0"></head><body class="is-2-column"><script type="text/javascript" src="/js/imaegoo/night.js"></script><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2019-11-01T22:29:44.000Z" title="2019-11-01T22:29:44.000Z">2019-11-02</time>发表</span><span class="level-item"><time dateTime="2020-03-05T05:03:58.184Z" title="2020-03-05T05:03:58.184Z">2020-03-05</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">25 分钟读完 (大约3714个字)</span><span class="level-item leancloud_visitors" id="/2019/11/02/Softmax-Classification/" data-flag-title="Softmax Classification"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="twikoo_visitors"><i class="fa fa-spinner fa-spin"></i></span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">Softmax Classification</h1><div class="content"><h2 id="什么是softmax"><a href="#什么是softmax" class="headerlink" title="什么是softmax"></a>什么是softmax</h2><p>对于一个输入$x$, 我们想知道它是N个类别中的哪一类<br>假设我们有一个模型，能对输入x输出N个类别的评分，评分越高说明x是这个类别的可能性越大，评分最高的被认为是$x$正确的类别。</p>
<a id="more"></a>
<p>然而，这样的评分范围很广，我们希望把它变成一个概率，而softmax就是一个能将$(-\infty,+\infty)$的一组评分转化为一组概率，并让它们的和为1的归一化的函数（squashing function），而且这个函数是保序的，原来大的评分转换后的概率大，而小的评分对应的概率小。<br>为了达到这个<code>squashing</code>的目的，softmax 被定义为：<br>$$<br>y_{i} = \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}} \ \ \ \forall i \in 1…C<br>$$<br>其中${s_i}$表示模型对输入$x$在第i个类别上的评分值,$e$指数的作用是将$(-\infty,+\infty)$的评分变为$(0,+\infty)$，而不影响相对大小关系，而分母的求和是用来归一化的，使得它们加起来等于1<br>这样就可以将一组评分转化为一组概率，总概率和为1，而且保持相对大小关系。<br>举个例子，下图的softmax将6个评分转化为一组概率<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jb2anttyj31hm0rw40z.jpg"></p>
<h3 id="Softmax梯度"><a href="#Softmax梯度" class="headerlink" title="Softmax梯度"></a>Softmax梯度</h3><p>对<code>softmax</code>函数进行求导，即求<br>$$<br>\frac{\partial{y_{i}}}{\partial{a_{j}}}<br>$$<br>第$i$项的输出对第$j$项输入的偏导。<br>代入<code>softmax</code>函数表达式，可以得到：<br>$$<br>\frac{\partial y_i}{\partial a_j}=\frac{\partial \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}}{\partial a_j}<br>$$</p>
<p>用我们高中就知道的求导规则：对于<br>$$<br>f(x) = \frac{g(x)}{h(x)}<br>$$<br>它的导数为<br>$$<br>f’(x) = \frac{g’(x)h(x) - g(x)h’(x)}{[h(x)]^2}<br>$$<br>所以在我们这个例子中，<br>$$<br>g(x) = e^{a_i} \ h(x) = \sum_{k=1}^{C}e^{a_k}<br>$$</p>
<p>上面两个式子只是代表直接进行替换，而非真的等式。<br>$e^{a_i}$（即$g(x)$）对${a_j}$进行求导，要分情况讨论：</p>
<p>1.如果$i=j$，则求导结果为$e^{a_i}$</p>
<p>2.如果$i \neq j$，则求导结果为0</p>
<p>再看$\sum_{k=1}^{C}e^{a_k}$对${a_j}$求导，结果为$e^{a_i}$</p>
<p>所以，当$i=j$时：<br>$$<br>\frac{\partial y_i}{\partial a_j}=\frac{\partial \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}}{\partial a_j}=\frac{e^{a_i}\sum -e^{a_i}-e^{a_j}}{\sum ^{2}}=\frac{e^{a_i}}{\sum } \frac{\sum -e^{a_j}}{\sum }={y_i}({1-y_i})<br>$$</p>
<p>当$i \neq j$时：<br>$$<br>\frac{\partial y_i}{\partial a_j}=\frac{\partial \frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}}{\partial a_j}=\frac{0-e^{a_i}e^{a_j}}{\sum ^{2}}=-\frac{e^{a_i}}{\sum }\frac{e^{a_j}}{\sum }=-{y_i}{y_j}<br>$$</p>
<p>其中，为了方便，令$\Sigma = \sum_{k=1}^{C}e^{a_k}$</p>
<p>对<code>softmax</code>函数的求导，我在两年前微信校招面试基础研究岗位一面的时候，就遇到过，这个属于比较基础的问题。</p>
<h3 id="softmax的计算与数值稳定性"><a href="#softmax的计算与数值稳定性" class="headerlink" title="softmax的计算与数值稳定性"></a>softmax的计算与数值稳定性</h3><p>在Python中，<code>softmax</code>函数为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    exp_x = np.exp(x)</span><br><span class="line">    <span class="keyword">return</span> exp_x / np.<span class="built_in">sum</span>(exp_x)</span><br></pre></td></tr></table></figure>
<p>传入[1,2,3,4]的向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; softmax([1, 2, 3, 4, 5])</span><br><span class="line">array([ 0.01165623,  0.03168492,  0.08612854,  0.23412166,  0.63640865])</span><br></pre></td></tr></table></figure>
<p>但如果输入值较大时：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; softmax([1000, 2000, 3000, 4000, 5000])</span><br><span class="line">array([ nan,  nan,  nan,  nan,  nan])</span><br></pre></td></tr></table></figure>
<p>这是因为在求exp(x)时候溢出了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line">math.exp(1000)</span><br><span class="line"># Traceback (most recent call last):</span><br><span class="line">#   File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;</span><br><span class="line"># OverflowError: math range error</span><br></pre></td></tr></table></figure>
<p>一种简单有效避免该问题的方法就是让exp(x)中的x值不要那么大或那么小，在<code>softmax</code>函数的分式上下分别乘以一个非零常数：</p>
<p>$$<br>{y_i}=\frac{e^{a_i}}{\sum_{k=1}^{C}e^{a_k}}=\frac{Ee^{a_i}}{\sum_{k=1}^{C}Ee^{a_k}}=\frac{e^{a_i+log(E)}}{\sum_{k=1}^{C}e^{a_k+log(E)}}=\frac{e^{a_i+F}}{\sum_{k=1}^{C}e^{a_k+F}}<br>$$</p>
<p>这里$log(E)$是个常数，所以可以令它等于$F$。加上常数$F$之后，等式与原来还是相等的，所以我们可以考虑怎么选取常数$F$。我们的想法是让所有的输入在0附近，这样$e^{a_i}$的值不会太大，所以可以让F的值为：<br>$$<br>F = -max(a_1, a_2, …, a_C)<br>$$</p>
<p>这样子将所有的输入平移到0附近（当然需要假设所有输入之间的数值上较为接近），同时，除了最大值，其他输入值都被平移成负数，$e$<br>为底的指数函数，越小越接近0，这种方式比得到<code>nan</code>的结果更好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span>(<span class="params">x</span>):</span></span><br><span class="line">    shift_x = x - np.<span class="built_in">max</span>(x)</span><br><span class="line">    exp_x = np.exp(shift_x)</span><br><span class="line">    <span class="keyword">return</span> exp_x / np.<span class="built_in">sum</span>(exp_x)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; softmax([1000, 2000, 3000, 4000, 5000])</span><br><span class="line">array([ 0.,  0.,  0.,  0.,  1.])</span><br></pre></td></tr></table></figure>
<p>当然这种做法也不是最完美的，因为<code>softmax</code>函数不可能产生0值，但这总比出现<code>nan</code>的结果好，并且真实的结果也是非常接近0的。</p>
<h2 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h2><blockquote>
<p>如果单讲softmax这里已经结束了，它不过是一个<code>squashing function</code>但这对一个分类器是不完整的，我们想知道前面这个评分模型怎么做，如果前面的模型不合理，加上softmax也没有任何意义，因此前面这个评分模型才是整个softmax分类器的关键。本节带大家认识线性模型</p>
</blockquote>
<p>线性模型想法很简单，对于一个有n个属性的输入𝑥，它是i类别的评分被认为可以被𝑥属性值的线性组合（加权和）确定，线性组合的组合系数(向量)记为${\theta_i}$。<br>$$<br>x=\left( \begin{align}<br>  {x_1} \<br>  {\vdots} \<br>  {x_n} \<br>\end{align} \right)<br>$$</p>
<p>$$<br>\theta_i = (\theta_{i1},\cdots,\theta_{in})<br>$$</p>
<p>$$<br>score_i= \theta_ix=\theta_{i1}x_1 +\cdots+\theta_{in}x_n<br>$$</p>
<p>$$<br>i=1…N(假设有N类)<br>$$</p>
<h2 id="带核函数的模型"><a href="#带核函数的模型" class="headerlink" title="带核函数的模型"></a>带核函数的模型</h2><blockquote>
<p>线性模型简单，但是适用性有限，很多时候直接对属性进行线性评分是不合理的。可能不同属性之间有非线性的关联，单个属性值与评分之间也不一定是单调的线性关系，比如可能是中间大，两边小。因此我们需要考虑更复杂的模型，这里介绍一种基于已有数据的评分模型：<strong>核模型</strong></p>
</blockquote>
<p><strong>核模型</strong>没有直接去建模属性之间潜在的复杂关系，而是尝试用已知<strong>数据</strong>衡量新的输入。（和KNN有类似的思想）（顺便提一下，支持向量机中的核技巧也是类似的思想，SVM提到的各种空间映射，各种对偶的推导，都是其花哨的外表，而不是其基于<strong>数据</strong>的本质）</p>
<h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>进入正题前，先介绍一下核函数<br>核函数有很多种，这里介绍一种：高斯核，也叫RBF(径向基函数)，被定义为：<br>$$<br>k(x,c) = e^{-\frac{ {\left| x-c \right|}^2}{2} }<br>$$<br>其中$c$是常量<br>下图是一个二维RBF函数示意图，最高点对应的是$x=c$时的取值 直观地看，$x$取值越接近$c$则核函数取值越大<br>根据RBF定义式，这个接近是用二范数，也就是欧氏距离度量的<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbd3ayqfj30kg0fmgnb.jpg"></p>
<h3 id="核模型的评分"><a href="#核模型的评分" class="headerlink" title="核模型的评分"></a>核模型的评分</h3><p>假设数据点越接近，则性质越相似（试问这种假设是否合理？）<br>然后，将评分定义为输入$x$到所有已知数据点接近程度(RBF值)的线性组合, 如果输入$x$和已知数据点是同一类别则组合系数大，而若是不同类别则组合系数小，那么当输入$x$接近同类数据点时评分就会高，而接近异类数据点时评分就会低（甚至为负）。<br>如此一来，就可以达到根据已知数据对输入的类别进行预测的目的（同类别评分高，而不同类别评分低）</p>
<p>考虑第i个类别的评分为${score_i}$，已知$m$个数据点，$x^{(1)},\cdots,x^{(m)}$均为常量<br>$$<br>score_i={ {\theta }_{i} }\left( \begin{align}<br> k(x,{ {x}^{(1)} }) \<br> k(x,{ {x}^{(2)} }) \<br> \vdots  \<br> k(x,{ {x}^{(m)} }) \<br>\end{align} \right)<br>$$</p>
<p>$$<br>\theta_i = (\theta_{i1},\cdots,\theta_{im})<br>$$</p>
<p>$$<br>i=1…N(假设有N类)<br>$$</p>
<h2 id="神经网络-softmax"><a href="#神经网络-softmax" class="headerlink" title="神经网络+softmax"></a>神经网络+softmax</h2><blockquote>
<p>基于RBF的核模型最大问题在上面越接近越相似的假设不一定成立</p>
</blockquote>
<p>距离接近程度与评分不一定有简单线性关系，因为RBF考虑的是欧式距离，而数据可能是在复杂流形中分布的，例如一张对折的纸，上下挨着的两点欧式距离很近，但在纸张这个平面上的距离可能很远。<br>举个实际的例子，下面四副图片，第一幅是原图，右边三幅图片与第一幅图片的欧式距离相同（把图片像素看作向量分量计算距离），但他们的相似程度，或者评分应该相同吗？显然不是，第三幅图已经看不出是什么人了。<br><img src="https://tva1.sinaimg.cn/large/006y8mN6gy1g8jbnt2b1yj31800cq0up.jpg"><br>由此我们看到了传统统计方法的瓶颈和理论缺陷，这种缺陷在高维数据上尤为明显（例如图片）。而后来的深度学习正是尝试突破这种瓶颈，尝试找到数据更本质规律的有益探索。</p>
<p>深度学习是基于在神经网络的，神经网络本质上就是对数据做非线性变换，使得变换后的数据可以经过线性模型正确分类，这是神经网络用于分类任务最基本的想法————变换数据，使其线性可分。</p>
<p>然而浅层神经网络并不成功，这种变换是难以学习的，让神经网络火起来的还是深度学习。至于深度学习是如何发现数据更本质的规律的，请期待后续文章。</p>
<h2 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h2><blockquote>
<p>上面的内容讲到了各种模型，可是模型参数怎么确定呢, 下面讲三种方法</p>
</blockquote>
<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>上面讲过了，softmax输出的是一组概率，一个分布。 下面我们用极大似然估计的方法估计参数${\theta}$（就是上文提到的${\theta}$）<br>假设当前输入为${x_1,x_2,\cdots,x_m}$，${y_i}$表示${x_i}$的正确标签类别，似然函数可定义为:<br>$$<br>L(\theta)=p(y_1 |\ x_1,\theta)\cdot p(y_2 |\ x_2,\theta)\cdots  p(y_m |\ x_m,\theta)<br>$$<br>使得似然函数最大化：<br>$$<br>\theta = argmax\ log(L(\theta))<br>$$<br>等价于：<br>$$<br>\theta = argmin(-\sum_{i=1}^mlog(\ p(y_{i} |\ x_i,\theta)\ ))<br>$$<br>使得似然函数最大化的参数就是极大似然估计希望得到的参数，因此可以定义以下损失函数, 然后用梯度下降逼近最优解<br>$$<br>Loss = -\sum_{i=1}^mlog(\ p(y_{i} |\ x_i,\theta)\ )<br>$$</p>
<h3 id="Gradient-of-log-likelihood"><a href="#Gradient-of-log-likelihood" class="headerlink" title="Gradient of log likelihood"></a>Gradient of log likelihood</h3><blockquote>
<p>为了计算对数似然的梯度，我们需要显式地对$\hat{p}$进行归一化</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg"></p>
<blockquote>
<p>与未标准化的y分数相关的梯度采用一种特别简单的形式:<br><img src="https://tva1.sinaimg.cn/large/00831rSTly1gciyvjy3hbj30a906ft93.jpg"></p>
</blockquote>
<h3 id="KL散度和交叉熵"><a href="#KL散度和交叉熵" class="headerlink" title="KL散度和交叉熵"></a>KL散度和交叉熵</h3><p>对于一个输入${x_i}$,softmax输出的是一组概率$q_i=[q_{i1},\cdots,q_{iN}]$，一个分布，这个分布和真实分布${p_i}$(例如$p_i=[0,0,0,1,0,0]$)存在差异。从信息熵的角度，我们可以直接用KL散度衡量两个分布的差异，然后最小化这个差异得到的参数𝜃就是我们想要的结果。</p>
<p>因此可以定义损失函数：<br>$$<br>Loss = \sum_{i=1}^N KL(p_i||q_i)<br>$$<br>根据KL散度的定义，可以展开为<br>$$<br>Loss = \sum_{i=1}^N H(p_i,q_i) - H(p_i)<br>$$<br>${p_i}$向量只有一个分量取值为1, 其它全为0, 因此$H(p_i)\equiv0$ 所以，可以仅用交叉熵$H(p_i,q_i)$表示损失函数<br>$$<br>Loss = \sum_{i=1}^N H(p_i,q_i)<br>$$</p>
<p>$$<br>Loss = \sum_{i=1}^N p_{it}log(q_{it})<br>$$</p>
<p>$t$表示${p_i}$为1的那个分量<br>如果使用上一节定义的符号则可以改写为<br>$$<br>Loss = -\sum_{i=1}^mlog(\ p(y_{i} |\ x_i,\theta)\ )<br>$$</p>
<h4 id="LOSS-function求导"><a href="#LOSS-function求导" class="headerlink" title="LOSS function求导"></a>LOSS function求导</h4><p>对于所有样本，我们有以下loss function:<br>$$<br>L = -\sum_{k = 1}^{n}\sum_{i = 1}^{C}t_{ki} log(y_{ki})<br>$$<br>其中${t_{ki}}$是样本$k$属于类别$i$的概率，${y_{ki}}$是模型对样本$k$预测为属于类别$i$的概率</p>
<p>对于单个样本来说，loss function ${l_{CE}}$对输入${a_j}$的导数为：<br>$$<br>\frac{\partial l_{CE}}{\partial a_j}=-\sum_{i=1}^{C}\frac{\partial t_ilog(y_i)}{\partial a_j}=-\sum_{i=1}^{C}{t_i}\frac{\partial log(y_i)}{\partial a_j}=-\sum_{i=1}^{C}{t_i}\frac{1}{y_i}\frac{\partial y_i}{\partial a_j}<br>$$<br>上面对$\frac{\partial y_i}{\partial a_j}$求导结果已经算出：</p>
<p>当$i=j$时：$\frac{\partial y_i}{\partial a_j}={y_i}(1-{y_j})$</p>
<p>当$i \neq j$时：$\frac{\partial y_i}{\partial a_j}=-{y_i}{y_j}$</p>
<p>所以，将求导结果代入上式：<br>$$<br>\begin{align*}<br>-\sum_{i=1}^{C}{t_i}\frac{1}{y_i}\frac{\partial y_i}{\partial a_j}<br>&amp;= -\frac{t_i}{y_i}\frac{\partial y_i}{\partial a_j}-\sum_{i\neq j}^{C}\frac{t_i}{y_i}\frac{\partial y_i}{\partial a_j}  \<br>&amp;=-\frac{t_i}{y_i}{y_i}(1-{y_j})-\sum_{i\neq j}^{C}\frac{t_i}{y_i}(-{y_i}{y_j}) \<br>&amp;=-{t_j}+{t_j}{y_j}+\sum_{i\neq j}^{C}{t_i}{y_j}=-{t_j}+\sum_{i=1}^{C}{t_i}{y_j} \<br>&amp;=-{t_j}+{y_j}\sum_{i=1}^{C}{t_i}={y_j}-{t_j}<br>\end{align*}<br>$$</p>
<h4 id="TensorFlow代码实现"><a href="#TensorFlow代码实现" class="headerlink" title="TensorFlow代码实现"></a>TensorFlow代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">label = tf.placeholder(<span class="string">&quot;float&quot;</span>, shape=[<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">w_fc1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>, <span class="number">1024</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b_fc1 = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">1024</span>]))</span><br><span class="line">h_fc1 = tf.matmul(x, w_fc1) + b_fc1</span><br><span class="line"></span><br><span class="line">w_fc2 = tf.Variable(tf.truncated_normal([<span class="number">1024</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b_fc2 = tf.Variable(tf.constant(<span class="number">0.1</span>, shape=[<span class="number">10</span>]))</span><br><span class="line">y = tf.matmul(h_fc1, w_fc2) + b_fc2</span><br><span class="line"></span><br><span class="line">cross_entropy = -tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=label, logits=y))</span><br></pre></td></tr></table></figure>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>从上面可以看出<strong>交叉熵</strong>,<strong>KL散度</strong>,<strong>极大似然估计</strong>这几种求解模型参数的方法，最终的结果都是等价的，由于交叉熵形式比较接近最终损失函数形式，人们默认交叉熵就是softmax分类器的损失函数。但是要注意，这三者的等价的关键在于标签只有一类是正确分类，这符合分类问题的定义。但如果你考虑的问题不是分类问题，或者标签是非平凡的（并不只有一类为1，其它全为0）,再使用<strong>交叉熵</strong>就不合理了。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Softmax Classification</p><p><a href="https://huzhiliang.com/2019/11/02/Softmax-Classification/">https://huzhiliang.com/2019/11/02/Softmax-Classification/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>ฅ´ω`ฅ</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2019-11-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2020-03-05</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%88%86%E7%B1%BB/">分类</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6/">极大似然</a><a class="link-muted mr-2" rel="tag" href="/tags/KL%E6%95%A3%E5%BA%A6/">KL散度</a></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/" alt="支付宝"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/" alt="微信"></span></a></div></div></div><div class="card"><nav class="post-navigation mt-4 level is-mobile card-content"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/11/03/Minimum-Absolute-Difference-in-BST/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Minimum Absolute Difference in BST</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/11/01/Binary-Search-Tree-Iterator/"><span class="level-item">Binary Search Tree Iterator</span><i class="level-item fas fa-chevron-right"></i></a></div></nav></div><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">161</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">97</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener" id="widget-follow">微博 Weibo</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div><a class="link-more button is-light is-small size-small" href="/friends/">查看更多</a></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/C/"><span class="level-start"><span class="level-item">C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Golang/"><span class="level-start"><span class="level-item">Golang</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/LeetCode/"><span class="level-start"><span class="level-item">LeetCode</span></span><span class="level-end"><span class="level-item tag">85</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="level-start"><span class="level-item">数据结构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">29</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/CNN/"><span class="level-start"><span class="level-item">CNN</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">迁移学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%A0%B4%E8%A7%A3/"><span class="level-start"><span class="level-item">破解</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">英语学习</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-05T05:41:28.000Z">2020-03-05</time></p><p class="title"><a href="/2020/03/05/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%89-%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95%E8%A7%A3%E7%A0%81/">条件随机场CRF(三) 模型学习与维特比算法解码</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-04T08:24:55.000Z">2020-03-04</time></p><p class="title"><a href="/2020/03/04/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%BA%8C-%E5%89%8D%E5%90%91%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E6%A0%87%E8%AE%B0%E5%BA%8F%E5%88%97%E6%A6%82%E7%8E%87/">条件随机场CRF(二) 前向后向算法评估标记序列概率</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-03T02:59:49.000Z">2020-03-03</time></p><p class="title"><a href="/2020/03/03/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BACRF-%E4%B8%80-%E4%BB%8E%E9%9A%8F%E6%9C%BA%E5%9C%BA%E5%88%B0%E7%BA%BF%E6%80%A7%E9%93%BE%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">条件随机场CRF(一)从随机场到线性链条件随机场</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-03-02T02:46:01.000Z">2020-03-02</time></p><p class="title"><a href="/2020/03/02/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E7%9A%84%E5%88%86%E8%AF%8D%E5%8E%9F%E7%90%86/">文本挖掘的分词原理</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/">NLP</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-02-20T01:01:00.000Z">2020-02-20</time></p><p class="title"><a href="/2020/02/20/optimize-water-distribution-in-a-village/">optimize water distribution in a village</a></p><p class="categories"><a href="/categories/LeetCode/">LeetCode</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2020/03/"><span class="level-start"><span class="level-item">三月 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">二月 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">一月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">十二月 2019</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/11/"><span class="level-start"><span class="level-item">十一月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/10/"><span class="level-start"><span class="level-item">十月 2019</span></span><span class="level-end"><span class="level-item tag">33</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/09/"><span class="level-start"><span class="level-item">九月 2019</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/08/"><span class="level-start"><span class="level-item">八月 2019</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/07/"><span class="level-start"><span class="level-item">七月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/05/"><span class="level-start"><span class="level-item">五月 2019</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/04/"><span class="level-start"><span class="level-item">四月 2019</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/03/"><span class="level-start"><span class="level-item">三月 2019</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/02/"><span class="level-start"><span class="level-item">二月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/01/"><span class="level-start"><span class="level-item">一月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">八月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">七月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">五月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">三月 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/02/"><span class="level-start"><span class="level-item">二月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/01/"><span class="level-start"><span class="level-item">一月 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/12/"><span class="level-start"><span class="level-item">十二月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/11/"><span class="level-start"><span class="level-item">十一月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/10/"><span class="level-start"><span class="level-item">十月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/09/"><span class="level-start"><span class="level-item">九月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/07/"><span class="level-start"><span class="level-item">七月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/06/"><span class="level-start"><span class="level-item">六月 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/05/"><span class="level-start"><span class="level-item">五月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/03/"><span class="level-start"><span class="level-item">三月 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/02/"><span class="level-start"><span class="level-item">二月 2017</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/04/"><span class="level-start"><span class="level-item">四月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/02/"><span class="level-start"><span class="level-item">二月 2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Array/"><span class="tag">Array</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Attention/"><span class="tag">Attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Binary-Tree/"><span class="tag">Binary Tree</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CFG/"><span class="tag">CFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CPU/"><span class="tag">CPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CYK/"><span class="tag">CYK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Caffee/"><span class="tag">Caffee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/English/"><span class="tag">English</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Facebook/"><span class="tag">Facebook</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GBDT/"><span class="tag">GBDT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPU/"><span class="tag">GPU</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GRN/"><span class="tag">GRN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GloVe/"><span class="tag">GloVe</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go/"><span class="tag">Go</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Google-apac/"><span class="tag">Google apac</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Go%E8%AF%AD%E8%A8%80/"><span class="tag">Go语言</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Greedy/"><span class="tag">Greedy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HMM/"><span class="tag">HMM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/IBM-Modes/"><span class="tag">IBM Modes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL%E6%95%A3%E5%BA%A6/"><span class="tag">KL散度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LeetCode/"><span class="tag">LeetCode</span><span class="tag">31</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexicalized-PCFG/"><span class="tag">Lexicalized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lexized-PCFG/"><span class="tag">Lexized PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Linear-Models/"><span class="tag">Log-Linear Models</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PCFG/"><span class="tag">PCFG</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Programmer/"><span class="tag">Programmer</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Pytorch/"><span class="tag">Pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Queue/"><span class="tag">Queue</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Seq2seq/"><span class="tag">Seq2seq</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tagging/"><span class="tag">Tagging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tencent/"><span class="tag">Tencent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow/"><span class="tag">Tensorflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VIP/"><span class="tag">VIP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Viterbi/"><span class="tag">Viterbi</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-representation/"><span class="tag">Word representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XGBoost/"><span class="tag">XGBoost</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/exhaustive-search/"><span class="tag">exhaustive search</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spark/"><span class="tag">spark</span><span class="tag">23</span></a></div><div class="control"><a class="tags has-addons" href="/tags/turtle/"><span class="tag">turtle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/word2vec/"><span class="tag">word2vec</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%93%E9%A2%98/"><span class="tag">专题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"><span class="tag">二分搜索</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E6%A0%91/"><span class="tag">二分搜索树</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E5%88%86%E6%A0%91/"><span class="tag">二分树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"><span class="tag">二进制</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"><span class="tag">优化算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E7%B1%BB/"><span class="tag">分类</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E8%AF%8D/"><span class="tag">分词</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%91%E6%8C%87offer/"><span class="tag">剑指offer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E5%9B%9E%E5%BD%92/"><span class="tag">动态回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"><span class="tag">动态规划</span><span class="tag">22</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%9E%E5%BD%92/"><span class="tag">回归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E8%AE%BA/"><span class="tag">图论</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%92%E5%BA%8F/"><span class="tag">排序</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"><span class="tag">数学原理</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="tag">数据分析</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"><span class="tag">条件随机场</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6/"><span class="tag">极大似然</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/"><span class="tag">模型压缩</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/"><span class="tag">模型部署</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%88%E6%9D%83/"><span class="tag">版权</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E6%8A%BD%E5%8F%96/"><span class="tag">特征抽取</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"><span class="tag">算法原理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95%E5%A4%8D%E6%9D%82%E5%BA%A6/"><span class="tag">算法复杂度</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">线性模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%84%E5%90%88%E6%A0%91/"><span class="tag">组合树</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E5%85%B8%E7%BD%91%E7%BB%9C/"><span class="tag">经典网络</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"><span class="tag">统计机器翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90/"><span class="tag">网易云音乐</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%81%9A%E7%B1%BB/"><span class="tag">聚类</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"><span class="tag">背包问题</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%84%9A%E6%9C%AC/"><span class="tag">脚本</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E6%B3%95/"><span class="tag">语法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"><span class="tag">语言模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4/"><span class="tag">超参数调整</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/"><span class="tag">迁移学习</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%80%92%E5%BD%92/"><span class="tag">递归</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%82%AE%E4%BB%B6/"><span class="tag">邮件</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%93%BE%E8%A1%A8/"><span class="tag">链表</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%99%8D%E7%BB%B4/"><span class="tag">降维</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%A2%E8%AF%95%E4%B8%93%E5%9C%BA/"><span class="tag">面试专场</span><span class="tag">2</span></a></div></div></div></div></div><div class="card widget" id="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img class="logo-img" src="/" alt="MCFON" height="28"><img class="logo-img-dark" src="/" alt="MCFON" height="28"></a><p class="is-size-7"><span>&copy; 2020 ฅ´ω`ฅ</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/imaegoo/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><a href="http://www.miitbeian.gov.cn" target="_blank">豫ICP备18017229号</a> - </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><div class="searchbox-pinyin"><label class="checkbox"><input id="search-by-pinyin" type="checkbox" checked="checked"><span> 拼音检索</span></label></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/imaegoo/pinyin.js" defer></script><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script><script type="text/javascript" src="/js/imaegoo/imaegoo.js"></script><script type="text/javascript" src="/js/imaegoo/universe.js"></script><script type="text/javascript" src="/js/live2d/autoload.js"></script></body></html>